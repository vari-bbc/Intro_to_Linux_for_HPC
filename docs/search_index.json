[["index.html", "Introductory Bioinformatics for VAI Users Part 1 Introduction", " Introductory Bioinformatics for VAI Users The Bioinformatics and Biostatistics Core (BBC) Part 1 Introduction This book is an introduction to practical bioinformatics, with a focus on the resources at the VAI. "],["basic-command-line-utilities-on-the-hpc.html", "Part 2 Basic Command Line Utilities on the HPC 2.1 Access HPC 2.2 File navigation 2.3 View and manipulate files 2.4 Exercise 2.5 Summary", " Part 2 Basic Command Line Utilities on the HPC 2.1 Access HPC Ensure that your laptop is connected to wifi “vai”, not “vai-guest”. archived content: previous ssh connection instructions Note: The platform-specific instructions below are hidden by default because of the newer HPC OnDemand platform, which we can all access from our laptops using a web browser. However, for archival purposes, we will still provide the platform-specific instructions to access the HPC on your laptop. 2.1.0.1 Mac users Open your terminal (search for the app) Type the following command to connect to the HPC. Replace firstname.lastname with your actual VAI username. ssh firstname.lastname@access.hpc.vai.org Enter your VAI password. (Note: you will not see the password as you type it, but it is working! Press your enter/return key when you’re done.) 2.1.0.2 Windows users If MobaXterm is not installed, please download the free MobaXterm version, then set up, and agree with license agreements to proceed installation. Open MobaXterm Click on Session in the top left corner Click on SSH(Secure Shell) Enter access.hpc.vai.org in the Remote host field Click the box on the left of Specify username, then enter your VAI username and password Click OK 2.1.1 OnDemand Instructions OnDemand is a web-based portal that lets you access the HPC resources right from your browser, without needing VPN or ssh tools on your local computer. You can read more about this on the HPC OnDemand sharepoint page. Below are the steps to access the HPC command line using OnDemand: Open a web browser (Chrome, Firefox, Safari, etc.) Go to the following URL: https://ondemand3.vai.zone/ if you see an error, try this instead: https://ondemandlocal.hpc.vai.org if neither or those links work, please let us know! Select “hpc Shell Access” from the list of several “pinned apps”. (“hpc Shell Access” is similar to the terminal on your laptop) Congrats – you’ve successfully connected to the HPC! 2.2 File navigation Practice directory: /varidata/researchtemp/hpctmp/BBC_workshop_Oct2024_II. 2.2.1 Navigate to a directory (folder) cd - Change Directory. Allows you to navigate to a different directory (folder). Note the following special symbols: . refers to the folder you’re currently in (your “working” directory). .. refers to the folder before where you currently are - this is your “parent” directory. / is the root directory. ~ is your personal home directory. pwd - Print Working Directory. Displays the current directory (folder) you are in. # Display the current directory pwd # Change to the practice directory cd /varidata/researchtemp/hpctmp/BBC_workshop_Oct2024_II # Display the current directory again to confirm the change pwd ## /home/kin.lau ## /varidata/researchtemp/hpctmp/BBC_workshop_Oct2024_II 2.2.2 List content in a directory ls - list contents (files and folders). Without anything specified after ls, it will list what’s in the current directory. ls -lht – list contents, with added options (-l more details in a long list, -h human-readable sizes, -t sorted by modification time). ls foldername - list contents of the specified folder. Shows more details about the files and folders, ls ls -lht ls -lht /varidata/researchtemp/hpctmp/BBC_workshop_Oct2024_II ls -lht ~ 2.2.3 Navigate back to home directory Without anything after cd, you will go to your home directory, which is /home/username (same as ~). # same as &quot;cd ~&quot; or &quot;cd /home/username&quot; cd # check: where are you now? pwd 2.2.4 Create a directory mkdir dir_name - will create a directory “dir_name” in your current directory. You will be creating a directory in your home drectory (because we just navigated to it). Make sure you are in your home directory first (use pwd), then create a directory called “hpc_workshop_2024” pwd mkdir hpc_workshop_2024 2.2.5 Copy a file cp - copy file/files Copy a file from /varidata/researchtemp/hpctmp/BBC_workshop_Oct2024_II to the directory you just created. pwd cp /varidata/researchtemp/hpctmp/BBC_workshop_Oct2024_II/metadata.tsv hpc_workshop_2024 ls hpc_workshop_2024 2.3 View and manipulate files 2.3.1 Display content cat - display the entire contents of a file. head - display the first 10 lines/rows of the a file. tail - display the last 10 lines/rows of the a file. You can use “-n” to control how many lines you want to see, default is 10. cd ~/hpc_workshop_2024 cat metadata.tsv head metadata.tsv tail metadata.tsv head -n 2 metadata.tsv The cat command can also be used to combine files. (This is where the command’s name comes from: concatenate) Note that we won’t run the command below, but keep this in mind for future reference. cat file1.txt file2.txt &gt; combined.txt 2.3.2 Pattern search grep - search a pattern by line pwd grep &quot;13&quot; metadata.tsv ## /home/kin.lau/hpc_workshop_2024 ## M 13 sample 13 replicate a ## Z 26 sample 13 replicate b 2.3.3 Display the number of lines, words, and characters wc - word count. It counts the number of lines, words, and characters in a file. Adding the -l option afterwards just gives the number of lines in the file. wc metadata.tsv wc -l metadata.tsv ## 26 156 675 metadata.tsv ## 26 metadata.tsv 2.3.4 Pipe - redirection A pipe is a form of redirection (instead of printing output to the screen, it sends it to other destinations). You can send output from one command/program to another for further processing, such as: command 1 | command 2 | command 3. Above, the output from command 1 is used as input for command 2, and the output from command 2 is used as input for command 3. In the example below, we will use 3 commands subsequently to count the number of lines that contain the number “13” in the file. cat metadata.tsv | grep &quot;13&quot; | wc -l ## 2 2.3.5 Output redirection Instead of printing output to your screen (typical command output) or another command (pipe), you can redirect the output to a file. &gt; - redirect output to a file. Note that it will overwrite the file if it already exists – be careful! &gt;&gt; - append output to a file. It will add the output to the end of the file. # note that no output will be displayed on the screen -- it&#39;s saved in the file instead grep &quot;13&quot; metadata.tsv &gt; lines_with_13.tsv # check: do we see the file we just created? ls # display the content of the file cat lines_with_13.tsv ## combined.fq ## data_01_R1.fq ## data_54_R1.fq ## lines_with_13.tsv ## metadata.tsv ## M 13 sample 13 replicate a ## Z 26 sample 13 replicate b 2.4 Exercise Below, we’ll be doing something similar to the exercises above, but with real genomic data! We’ll be using a fastq file (format containing raw sequencing &amp; quality information). We will: copy fastq files from the practice directory to the folder you created combine the two fastq files into one count the number of reads in the combined file See if you can do each step on your own – if you get stuck, don’t worry! Try to remember the commands we’ve learned so far, and you can always refer back to the examples above. To check your work, you can view the commands below. 2.4.1 Step 1: Copy the files Once you’re in your hpc_workshop_2024 directory, copy the files data_01_R1.fq and data_54_R1.fq from the practice directory (/varidata/researchtemp/hpctmp/BBC_workshop_Oct2024_II) into your folder. Click here to see a solution cd ~/hpc_workshop_2024 cp /varidata/researchtemp/hpctmp/BBC_workshop_Oct2024_II/data_01_R1.fq . cp /varidata/researchtemp/hpctmp/BBC_workshop_Oct2024_II/data_54_R1.fq . 2.4.2 Step 2: Combine the files Combine the two fastq files into one file called combined.fq. Click here to see a solution cat data_01_R1.fq data_54_R1.fq &gt; combined.fq ls ## combined.fq ## data_01_R1.fq ## data_54_R1.fq ## lines_with_13.tsv ## metadata.tsv 2.4.3 Step 3: Count the number of reads Count the number of reads in the combined file. Hint #1 – what is a “read”? In a fastq file, reads start with the “@” symbol. Hint #2 – how to approach this? See if you can combine a few commands together! Plan out each of the steps you need to do, then put them all together. Click here to see an example solution # use that combined file grep &quot;@&quot; combined.fq | wc -l # a different way to do the same thing cat combined.fq | grep &quot;@&quot; | wc -l # or, combine the commands all together cat data_01_R1.fq data_54_R1.fq | grep &quot;@&quot; | wc -l ## 500 ## 500 ## 500 Can you explain why your solution works? Which solution above does yours look most similar to? Congratulations! You’ve successfully completed the exercise. BONUS: If you have extra time, use the skills you’ve learned to explore the fastq file format further: Count the total number of lines in the combined file. Using your answer from the exercise above (count the number of reads) – how are the number of reads related to the total number of lines in the file? Look at some of the contents of the combined fastq file. What do you notice about the structure of the file? Can you find any patterns? What do you think each line represents? What are some questions you have about the fastq file format? 2.5 Summary In this section, we’ve covered the basic commands for navigating directories, viewing and manipulating files, using pipes, and redirecting output. You’ve learned how to: Navigate to a directory List content in a directory Create a directory Copy a file Display content Search for patterns Display the number of words, lines, and characters Use pipes for redirection Use output redirection These are the fundamental commands you’ll need to work with files and directories on the HPC. In the next section, we’ll work through a real bioinformatics “mini-project” that builds on these commands, so you can see how they can be used together to solve a problem. Next: Bioinformatics Mini Project "],["mini-project.html", "Part 3 Mini Project 3.1 Start an Interactive Job 3.2 Create Directory 3.3 Copy Fastq Files To fastqs subdirectory 3.4 Use basic Linux commands to explore the fastq files 3.5 Working With Environment Modules 3.6 Run FastQC 3.7 Set up a job script to run Salmon to align the reads 3.8 Submit a Job 3.9 Examine the Standard Output (stdout) and Standard Error (stderr) log files 3.10 Use grep to find the TPMs for a specific gene 3.11 BONUS: Use an interactive job to run multiQC on the Salmon and FastQC output", " Part 3 Mini Project Here, we will combine some of the commands we have learned today to perform a toy bioinformatic analysis. Two human paired-end samples (four total fastq files) have already been downloaded from GSE52778 and are in the directory /varidata/researchtemp/hpctmp/BBC_workshop_Oct2024_II/fastqs. To save time for the workshop, each file has been randomly subsetted to just a small fraction of the total reads. Here each user will: Copy these fastq files their own private project directory. Use basic Linux commands to learn some characteristics of these files. Use Salmon to align (pseudo-align) these reads to the hg38 reference transcriptome and get transcripts-per-million (TPMs) for each annotated gene. 3.1 Start an Interactive Job While simple file manipulations can be done on the submit node, computationally intensive operations should be performed using preallocated computational resources. An interactive job allows us to preallocate resources while still being able to run commands line by line. We will start an interactive job, requesting one CPU core and 1 hour and 30 minutes of walltime. srun -p short --nodes=1 --ntasks-per-node=1 --time=01:30:00 --pty bash After a job has been submitted, users can check on the status (e.g. how long it has been running) of it using the following. squeue --me 3.2 Create Directory Typically, one would work in their specific lab’s folder on the HPC. For this workshop, we will work in a common directory so that the instructors and check on your progress. cd /varidata/researchtemp/hpctmp/BBC_workshop_Oct2024_II/ Create a directory based on your username to separate your work from other users’. mkdir &lt;username&gt; Navigate to the username directory cd &lt;username&gt; Create a fastqs directory inside the username directory. It is good practice to keep your raw data separate from your analyses and never make changes to them directly. mkdir fastqs Use ls to confirm the fastqs directory was created. ls 3.3 Copy Fastq Files To fastqs subdirectory Verify the current directory is in the username directory. pwd Copy the 4 fastq.gz files and md5sum.txt, which you will use to check the validty of the files. cp /varidata/researchtemp/hpctmp/BBC_workshop_Oct2024_II/fastqs/*fastq.gz ./fastqs/ cp /varidata/researchtemp/hpctmp/BBC_workshop_Oct2024_II/fastqs/md5sum.txt ./fastqs/ Verify that the copied files are valid. The following code should return with an OK for each file. cd fastqs md5sum -c md5sum.txt ## SRR1039520_1.fastq.gz: OK ## SRR1039520_2.fastq.gz: OK ## SRR1039521_1.fastq.gz: OK ## SRR1039521_2.fastq.gz: OK Go back to the username directory. cd .. 3.4 Use basic Linux commands to explore the fastq files Notice all of the sequence data files end with a .gz extension, indicating they are gzip compressed. To view such files, one must use zcat instead of cat so that the files are decompressed into human-readable format. zcat fastqs/SRR1039520_1.fastq.gz | head ## @SRR1039520.19151550 19151550 length=63 ## CCAGGACATCAAGAAGCCAGCTGAAGATGAGTGGGGTAAAACCCCAGACGCCATGAAAGCTGC ## + ## HJJJJJJJJJJJJJJJIJJJJJJJJIJJJJJGGJJJFHIJIIJJIGHHFFFDDDDDCDDDCDD ## @SRR1039520.3404519 3404519 length=63 ## TGAGACATGGTTATAGATAAGAGAGTACAAAATGACTCTTTTTCCTGTCAATTGAAATTTAAA ## + ## HIGDFBGIIJBHGIIEHIIJIJIIIEGGIIIHGIJJIJJJIIJGIIIIGIEHIGDCHHIICG7 ## @SRR1039520.16253787 16253787 length=63 ## CAGGAGACCAAAGACACTGCAATTTGTGTGTTTTCTACAGGGTGCTTTAGATGACGTCTCATT zcat fastqs/SRR1039520_2.fastq.gz | head ## @SRR1039520.19151550 19151550 length=63 ## GAGATGGGGGTCCGTGCGGGCAGAACCCAGGGCATGAAGATCCAAAAGGGCCTGGTTCAGCTT ## + ## HJJJJJJJJJHHHIGIJIJJJJJJJHHHHFFFDDEEDDDDDDDDDDDDDDDDDDDDDDDDDDD ## @SRR1039520.3404519 3404519 length=63 ## TTTGACCCTAGTATTGGCAATAGCCCTTTGCTATTTATATAATTAAAACTTTTCTTTAAATTT ## + ## HIJIJJJJIIEHGIGIIIDGIJJJJIIJJJIJJJIJJJIIIJJJJIJJGCHIJJJJJIJIJII ## @SRR1039520.16253787 16253787 length=63 ## TACAGTTTGCAAAAGATGTCCAGATGGGTTCTTCTCAAATGAGACGTCATCTAAAGCACCCTG Notice that SRR1039520_1.fastq.gz and SRR1039520_2.fastq.gz files have the same read IDs. Valid paired fastq files always have matching read IDs throughout the entire file. Next, we can figure out how many reads are in a fastq file using wc -l. Recall that each read is represented by 4 lines in a fastq file, so we need to divide the results of wc -l by 4 to get the number of reads. zcat fastqs/SRR1039520_1.fastq.gz | wc -l ## 2000000 Finally, we can use wc -m to figure out the read length in a fastq file. Below, we use a combination of head -n2 and tail -n1 to get the second line of the first read. You may notice that the results of wc -m will be 1 higher than the actual read length. This is because the tool counts the newline character also. zcat fastqs/SRR1039520_1.fastq.gz | head -n2 | tail -n1 | wc -m ## 64 3.5 Working With Environment Modules Type module av bbc2 (modules beginning with just bbc are from the old HPC) to see all the software installed by the BBC. There are a lot of modules installed; to parse through these more easily, we can pipe the results of module av into grep to search for modules with specific keywords. There is a trick, though. The results of module av go to standard error, so we need to redirect standard error to standard out using 2&gt;&amp;1 before the pipe. This command will output any modules containing the fastqc keyword. module av -w 1 bbc2 2&gt;&amp;1 | grep &#39;fastqc&#39; ## bbc2/fastqc/fastqc-0.12.1 3.6 Run FastQC Create a fastqc directory inside of your username directory and run FastQC. module load bbc2/fastqc/fastqc-0.12.1 mkdir fastqc # Run FastQC. You can also run `fastqc -h` to see what different options do. fastqc -o fastqc fastqs/*fastq.gz ## Loading bbc2/fastqc/fastqc-0.12.1 ## Loading requirement: VARI/java/1.8.0_202 ## application/gzip ## application/gzip ## Started analysis of SRR1039520_1.fastq.gz ## application/gzip ## application/gzip ## Approx 5% complete for SRR1039520_1.fastq.gz ## Approx 10% complete for SRR1039520_1.fastq.gz ## Approx 15% complete for SRR1039520_1.fastq.gz ## Approx 20% complete for SRR1039520_1.fastq.gz ## Approx 25% complete for SRR1039520_1.fastq.gz ## Approx 30% complete for SRR1039520_1.fastq.gz ## Approx 35% complete for SRR1039520_1.fastq.gz ## Approx 40% complete for SRR1039520_1.fastq.gz ## Approx 45% complete for SRR1039520_1.fastq.gz ## Approx 50% complete for SRR1039520_1.fastq.gz ## Approx 55% complete for SRR1039520_1.fastq.gz ## Approx 60% complete for SRR1039520_1.fastq.gz ## Approx 65% complete for SRR1039520_1.fastq.gz ## Approx 70% complete for SRR1039520_1.fastq.gz ## Approx 75% complete for SRR1039520_1.fastq.gz ## Approx 80% complete for SRR1039520_1.fastq.gz ## Approx 85% complete for SRR1039520_1.fastq.gz ## Approx 90% complete for SRR1039520_1.fastq.gz ## Approx 95% complete for SRR1039520_1.fastq.gz ## Approx 100% complete for SRR1039520_1.fastq.gz ## Analysis complete for SRR1039520_1.fastq.gz ## Started analysis of SRR1039520_2.fastq.gz ## Approx 5% complete for SRR1039520_2.fastq.gz ## Approx 10% complete for SRR1039520_2.fastq.gz ## Approx 15% complete for SRR1039520_2.fastq.gz ## Approx 20% complete for SRR1039520_2.fastq.gz ## Approx 25% complete for SRR1039520_2.fastq.gz ## Approx 30% complete for SRR1039520_2.fastq.gz ## Approx 35% complete for SRR1039520_2.fastq.gz ## Approx 40% complete for SRR1039520_2.fastq.gz ## Approx 45% complete for SRR1039520_2.fastq.gz ## Approx 50% complete for SRR1039520_2.fastq.gz ## Approx 55% complete for SRR1039520_2.fastq.gz ## Approx 60% complete for SRR1039520_2.fastq.gz ## Approx 65% complete for SRR1039520_2.fastq.gz ## Approx 70% complete for SRR1039520_2.fastq.gz ## Approx 75% complete for SRR1039520_2.fastq.gz ## Approx 80% complete for SRR1039520_2.fastq.gz ## Approx 85% complete for SRR1039520_2.fastq.gz ## Approx 90% complete for SRR1039520_2.fastq.gz ## Approx 95% complete for SRR1039520_2.fastq.gz ## Approx 100% complete for SRR1039520_2.fastq.gz ## Analysis complete for SRR1039520_2.fastq.gz ## Started analysis of SRR1039521_1.fastq.gz ## Approx 5% complete for SRR1039521_1.fastq.gz ## Approx 10% complete for SRR1039521_1.fastq.gz ## Approx 15% complete for SRR1039521_1.fastq.gz ## Approx 20% complete for SRR1039521_1.fastq.gz ## Approx 25% complete for SRR1039521_1.fastq.gz ## Approx 30% complete for SRR1039521_1.fastq.gz ## Approx 35% complete for SRR1039521_1.fastq.gz ## Approx 40% complete for SRR1039521_1.fastq.gz ## Approx 45% complete for SRR1039521_1.fastq.gz ## Approx 50% complete for SRR1039521_1.fastq.gz ## Approx 55% complete for SRR1039521_1.fastq.gz ## Approx 60% complete for SRR1039521_1.fastq.gz ## Approx 65% complete for SRR1039521_1.fastq.gz ## Approx 70% complete for SRR1039521_1.fastq.gz ## Approx 75% complete for SRR1039521_1.fastq.gz ## Approx 80% complete for SRR1039521_1.fastq.gz ## Approx 85% complete for SRR1039521_1.fastq.gz ## Approx 90% complete for SRR1039521_1.fastq.gz ## Approx 95% complete for SRR1039521_1.fastq.gz ## Approx 100% complete for SRR1039521_1.fastq.gz ## Analysis complete for SRR1039521_1.fastq.gz ## Started analysis of SRR1039521_2.fastq.gz ## Approx 5% complete for SRR1039521_2.fastq.gz ## Approx 10% complete for SRR1039521_2.fastq.gz ## Approx 15% complete for SRR1039521_2.fastq.gz ## Approx 20% complete for SRR1039521_2.fastq.gz ## Approx 25% complete for SRR1039521_2.fastq.gz ## Approx 30% complete for SRR1039521_2.fastq.gz ## Approx 35% complete for SRR1039521_2.fastq.gz ## Approx 40% complete for SRR1039521_2.fastq.gz ## Approx 45% complete for SRR1039521_2.fastq.gz ## Approx 50% complete for SRR1039521_2.fastq.gz ## Approx 55% complete for SRR1039521_2.fastq.gz ## Approx 60% complete for SRR1039521_2.fastq.gz ## Approx 65% complete for SRR1039521_2.fastq.gz ## Approx 70% complete for SRR1039521_2.fastq.gz ## Approx 75% complete for SRR1039521_2.fastq.gz ## Approx 80% complete for SRR1039521_2.fastq.gz ## Approx 85% complete for SRR1039521_2.fastq.gz ## Approx 90% complete for SRR1039521_2.fastq.gz ## Approx 95% complete for SRR1039521_2.fastq.gz ## Approx 100% complete for SRR1039521_2.fastq.gz ## Analysis complete for SRR1039521_2.fastq.gz See what was produced by FastQC. ls fastqc/ ## SRR1039520_1_fastqc.html ## SRR1039520_1_fastqc.zip ## SRR1039520_2_fastqc.html ## SRR1039520_2_fastqc.zip ## SRR1039521_1_fastqc.html ## SRR1039521_1_fastqc.zip ## SRR1039521_2_fastqc.html ## SRR1039521_2_fastqc.zip 3.7 Set up a job script to run Salmon to align the reads First, we exit from our interactive job because we want to get back on to the submit node to submit a non-interactive job to run Salmon. # You should see one job when you run this command, corresponding to your interactive job. squeue --me # Exit the interactive job exit # Now you should see no jobs when you run this command because the interactive job has ended. squeue --me # Go back to your project directory cd /varidata/researchtemp/hpctmp/BBC_workshop_Oct2024_II/&lt;username&gt; Below is a SLURM job script to run Salmon. For now, do not worry about how the code works. Copy the code and paste it into a new file. Save it as run_salmon.sh in your username directory. If you have issues with this task, you can download the job script directly using the command, wget https://raw.githubusercontent.com/vari-bbc/Intro_to_Linux_for_HPC/refs/heads/main/resources/sec2/run_salmon.sh. #!/bin/bash #SBATCH --export=NONE #SBATCH -J run_salmon #SBATCH -o run_salmon.o #SBATCH -e run_salmon.e #SBATCH --ntasks 4 #SBATCH --time 1:00:00 #SBATCH --mem=31G start_time=$(date +&quot;%T&quot;) # You need to navigate to your project directory. Conveniently, the $SLURM_SUBMIT_DIR variable stores the path for where the job was submitted. cd ${SLURM_SUBMIT_DIR} module load bbc2/salmon/salmon-1.10.0 # Typically, you would have to first build an index before doing the aligning, but we have done this for you already. Here, we store the path to the index file in a variable called &#39;salmon_idx&#39;. salmon_idx=&quot;/varidata/research/projects/bbc/versioned_references/2022-03-08_14.47.50_v9/data/hg38_gencode/indexes/salmon/hg38_gencode/&quot; # make output directory for salmon mkdir -p salmon # This is called a for loop. We use this to run salmon quant on all the samples, one at a time. It is more efficient to run salmon on each sample &quot;in parallel&quot; but we will not do that today. for samp_id in SRR1039520 SRR1039521 do salmon quant -p ${SLURM_NTASKS} -l A -i $salmon_idx -1 fastqs/${samp_id}_1.fastq.gz -2 fastqs/${samp_id}_2.fastq.gz -o salmon/${samp_id} --validateMappings done end_time=$(date +&quot;%T&quot;) echo &quot;Start time: $start_time&quot; echo &quot;End time: $end_time&quot; 3.8 Submit a Job Type ls to ensure run_salmon.sh file exist in the username directory. ls Use the sbatch command to submit the job. sbatch -p short run_salmon.sh Users can check if the job is running with the following command. The job should take about two minutes to complete. squeue --me 3.9 Examine the Standard Output (stdout) and Standard Error (stderr) log files It is good practice to check the job logs after your job is done to ensure that the job completed successfully. If there is an error, the output files may not be reliable or could be incomplete. tail run_salmon.e ## [2025-10-03 10:29:55.282] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate ## [2025-10-03 10:29:55.309] [jointLog] [info] iteration = 0 | max rel diff. = 203.028 ## [2025-10-03 10:29:57.974] [jointLog] [info] iteration = 100 | max rel diff. = 19.6442 ## [2025-10-03 10:30:00.719] [jointLog] [info] iteration = 200 | max rel diff. = 0.462189 ## [2025-10-03 10:30:03.319] [jointLog] [info] iteration = 300 | max rel diff. = 1.92755 ## [2025-10-03 10:30:05.909] [jointLog] [info] iteration = 400 | max rel diff. = 0.0347574 ## [2025-10-03 10:30:07.538] [jointLog] [info] iteration = 463 | max rel diff. = 0.00959217 ## [2025-10-03 10:30:07.581] [jointLog] [info] Finished optimizer ## [2025-10-03 10:30:07.581] [jointLog] [info] writing output tail run_salmon.o ## Start time: 10:28:40 ## End time: 10:30:09 3.10 Use grep to find the TPMs for a specific gene As an example, let’s try to extract out the TPMs (Transcripts per Million) for MUC1. These values can be found in the quant.sf file in each sample’s folder. First, let’s take a look at one of these files to figure out the format of these files. head salmon/SRR1039520/quant.sf ## Name Length EffectiveLength TPM NumReads ## ENST00000456328.2 1657 1501.734 0.000000 0.000 ## ENST00000450305.2 632 476.867 0.000000 0.000 ## ENST00000488147.1 1351 1195.734 0.000000 0.000 ## ENST00000619216.1 68 2.021 0.000000 0.000 ## ENST00000473358.1 712 556.827 0.000000 0.000 ## ENST00000469289.1 535 379.986 0.000000 0.000 ## ENST00000607096.1 138 24.859 0.000000 0.000 ## ENST00000417324.1 1187 1031.734 0.000000 0.000 ## ENST00000461467.1 590 434.911 0.000000 0.000 From the output above, we can see that the TPMs are in the 4th column of this file. The canonical transcript for MUC1 is ENST00000620103, so we will search for that using grep. grep &#39;ENST00000620103&#39; salmon/SRR1039520/quant.sf ## ENST00000620103.4 1811 1655.734 0.000000 0.000 Look for MUC1 across all the samples at the same time. We can see that ‘SRR1039521’ has a TPM of 13.1 for MUC1 compared to 0 for ‘SRR1039520’. Recall that the fastq files for this exercise were subsetted to a very small number of reads so don’t interpret these results seriously. grep &#39;ENST00000620103&#39; salmon/*/quant.sf ## salmon/SRR1039520/quant.sf:ENST00000620103.4 1811 1655.734 0.000000 0.000 ## salmon/SRR1039521/quant.sf:ENST00000620103.4 1811 1655.512 13.182825 5.741 3.11 BONUS: Use an interactive job to run multiQC on the Salmon and FastQC output In this final step, users will start an interactive job to perform multiQC to collect and summarize the outcomes from FastQC and Salmon, then evaluate the quality of the fastq sequences with the reference transcriptome(mapping rate). Start an interactive job. srun --nodes=1 --ntasks-per-node=1 --time=00:30:00 --pty bash Navigate to the project directory. cd /varidata/researchtemp/hpctmp/BBC_workshop_Oct2024_II/&lt;username&gt; Load the environment module for multiQC. Run multiQC, which will summarize the results from FastQC and Salmon and output the results into a new directory called multiqc/. module load bbc2/multiqc/multiqc-1.14 multiqc --outdir multiqc . ## ## /// MultiQC 🔍 | v1.14 ## ## | multiqc | MultiQC Version v1.31 now available! ## | multiqc | Search path : /varidata/research/projects/bbc/research/Intro_to_Linux_for_HPC_devel ## | searching | ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 143/143 ## | fastqc | Found 4 reports ## | multiqc | Compressing plot data ## | multiqc | Report : multiqc/multiqc_report.html ## | multiqc | Data : multiqc/multiqc_data ## | multiqc | MultiQC complete List the contents of the multiqc directory. ls multiqc ## multiqc_data ## multiqc_report.html Note the newly created multiqc_report.html file. Try to view this file in your preferred internet browser. If you have mounted the HPC file system to your computer, you can simply double-click on this file. Alternatively, you can copy this file to your computer’s local storage first and then open it. "],["basic-rna-seq-analysis-from-fastq-files-to-de-genes.html", "Part 4 Basic RNA-Seq Analysis – From fastq files to DE genes 4.1 Run the BBC pipeline to align the reads 4.2 Symlink pre-run results to your directory 4.3 Quality control 4.4 DE analysis using R and DESeq2 4.5 Volcano plot 4.6 Make a new SummarizedExperiment to store all results 4.7 Heatmap of top DE genes 4.8 Look for specific genes 4.9 SummarizedExperiment exercises 4.10 Your turn 4.11 Venn diagrams 4.12 Upset plots", " Part 4 Basic RNA-Seq Analysis – From fastq files to DE genes 4.1 Run the BBC pipeline to align the reads 4.1.1 The workflow as a graph The workflow. 4.1.2 Clone the Github repo First, go to VAI OnDemand and click on “Apps” &gt; “hpc Shell Access”. Instructions for running the RNA-seq workflow are on the Github README, but here we will go through each step in more detail. For a normal project, you would be working in your lab’s storage space, but for today we will work in the hpctmp folder. cd /varidata/researchtemp/hpctmp/BBC_workshop_Oct2024_III/ mkdir &lt;username&gt; cd &lt;username&gt; git clone https://github.com/vari-bbc/rnaseq_workflow.git rnaseq_workflow_testrun The Github repository consisting of the RNA-seq workflow should now be downloaded in a folder named rnaseq_workflow_testrun. cd rnaseq_workflow_testrun ls 4.1.3 Add your fastq files to raw_data/ Instead of making multiple copies of the same file, which can quickly use up your lab’s storage quota, we can use symbolic links. The sequence data that we will be using for this workshop are from the airway dataset referenced in the DESeq2 vignette. The gene counts can actually be downloaded as an R package. ls ../../0_fastqs/ ln -sr ../../0_fastqs/* ./raw_data You can see where the symbolic links are pointing to using ls -l. ls -l ./raw_data 4.1.4 Fill out the samplesheet The samplesheet is a tab-delimited file within config/samplesheet/ and is named units.tsv. The easiest way to fill this out is to run the helper script, make_units_template.sh, to generate a template, then edit using a text editor. FOR THIS WORKSHOP, NO CHANGES NEED TO BE MADE. cd config/samplesheet/ ./make_units_template.sh There should now be a file named ‘units_template.tsv’. ls We can replace the ‘units.tsv’ with ‘units_template.tsv’. cp units_template.tsv units.tsv Use cat to look at the samplesheet. cat units.tsv The “group” column in units.tsv needs to be edited. Use the built-in editor in OnDemand to correct this column according to the values below. Tip: Within the OnDemand file explorer, click ‘Change directory’ and type /varidata/researchtemp/hpctmp/BBC_workshop_Oct2024_III/&lt;username&gt;/rnaseq_workflow_testrun/config/samplesheet to navigate directly to the correct folder. sample group SRR1039508 trt SRR1039509 untrt SRR1039512 trt SRR1039513 untrt SRR1039516 trt SRR1039517 untrt SRR1039520 trt SRR1039521 untrt Go back to the base level of the project directory. cd ../.. Make sure you are at /varidata/researchtemp/hpctmp/BBC_workshop_Oct2024_III/&lt;username&gt;/rnaseq_workflow_testrun. pwd 4.1.5 Fill out the config file The config file is a YAML file indicating the locations of reference files and also contains options for the workflow that you can turn off or turn on. Typically, the main thing is to specify reference files corresponding to the species you have sequenced (human, mouse, or rat etc). For this workshop, we are dealing with human data so we will align to the hg38 reference. Index files allow alignment algorithms to align reads to specific reference sequences. FOR THIS WORKSHOP, NO CHANGES NEED TO BE MADE BECAUSE THE CORRECT INFORMATION HAVE ALREADY BEEN ENTERED. cat config/config.yaml 4.1.6 Submit the main Snakemake job If your lab has their own nodes that you wish to use, use sbatch -p &lt;lab_name&gt; bin/run_snake.sh instead of the command below. sbatch bin/run_snake.sh 4.1.7 BBC-maintained reference files For future reference, the BBC downloads and maintains commonly used files and indexes for several model species. These files are version controlled to promote reproducibility in case you need to rerun an analysis or you want to run the exact same analysis on different datasets. ls /varidata/research/projects/bbc/versioned_references/ ## 2021-04-09_12.44.55_v1 ## 2021-07-02_11.23.48_v3 ## 2021-07-13_09.57.31_v4 ## 2021-08-02_20.40.24_v5 ## 2021-08-10_11.12.27_v6 ## 2021-10-25_15.31.38_v7 ## 2022-01-26_13.39.07_v8 ## 2022-03-08_14.47.50_v9 ## 2022-10-06_14.25.40_v10 ## 2022-12-19_13.27.04_v11 ## 2023-05-03_15.28.41_v12 ## 2023-10-04_10.07.51_v13 ## 2023-10-06_11.13.48_v14 ## 2023-11-08_15.45.32_v15 ## 2023-11-09_09.38.05_v16 ## 2024-10-31_10.56.03_v17 ## 2025-02-04_16.03.25_v18 ## 2025-04-30_23.47.46_v19 ## 2025-05-12_16.16.50_v20 ## latest ## regarding_v2.txt ls /varidata/research/projects/bbc/versioned_references/2023-05-03_15.28.41_v12/data/ ## GRCz11 ## c.elegans-WBcel235 ## dm6_BDGP6.28.100 ## e.coli-K12-mg1665_ensembl ## hg19_gencode ## hg19_gencode_plus_ERCC92 ## hg19_gencode_plus_viruses ## hg38_gencode ## mm10_gencode ## mm10_gencode_plus_ERCC92 ## mm10_gencode_plus_e.coli-K12-mg1665_ensembl ## mm10_gencode_plus_viruses_and_cfmedips ## mm11_gencode ## mm9_ucsc ## mm_BALB_CJ ## mm_BALB_CJ_plus_viruses_and_cfmedips ## mm_FVB_NJ ## mm_FVB_NJ_plus_viruses_and_cfmedips ## rnor6_ensembl The source of these files can be found in the species.tsv file. cat /varidata/research/projects/bbc/versioned_references/2023-05-03_15.28.41_v12/bin/species.tsv | cut -f2-3 ## id genome_fasta ## mm10_gencode ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M24/GRCm38.primary_assembly.genome.fa.gz ## hg38_gencode ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_33/GRCh38.primary_assembly.genome.fa.gz ## e.coli-K12-mg1665_ensembl ftp://ftp.ensemblgenomes.org/pub/release-47/bacteria//fasta/bacteria_0_collection/escherichia_coli_str_k_12_substr_mg1655/dna/Escherichia_coli_str_k_12_substr_mg1655.ASM584v2.dna.chromosome.Chromosome.fa.gz ## hg19_gencode ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_36/GRCh37_mapping/GRCh37.primary_assembly.genome.fa.gz ## dm6_BDGP6.28.100 ftp://ftp.ensembl.org/pub/release-100/fasta/drosophila_melanogaster/dna/Drosophila_melanogaster.BDGP6.28.dna.toplevel.fa.gz ## c.elegans-WBcel235 http://ftp.ensembl.org/pub/release-103/fasta/caenorhabditis_elegans/dna/Caenorhabditis_elegans.WBcel235.dna.toplevel.fa.gz ## mm_BALB_CJ http://ftp.ensembl.org/pub/release-104/fasta/mus_musculus_balbcj/dna/Mus_musculus_balbcj.BALB_cJ_v1.dna.toplevel.fa.gz ## mm_FVB_NJ http://ftp.ensembl.org/pub/release-104/fasta/mus_musculus_fvbnj/dna/Mus_musculus_fvbnj.FVB_NJ_v1.dna.toplevel.fa.gz ## rnor6_ensembl http://ftp.ensembl.org/pub/release-104/fasta/rattus_norvegicus/dna/Rattus_norvegicus.Rnor_6.0.dna.toplevel.fa.gz ## GRCz11 https://ftp.ensembl.org/pub/release-108/fasta/danio_rerio/dna/Danio_rerio.GRCz11.dna.toplevel.fa.gz ## mm11_gencode https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M31/GRCm39.primary_assembly.genome.fa.gz ## mm9_ucsc ftp://hgdownload.cse.ucsc.edu/goldenPath/mm9/bigZips/mm9.fa.gz The versions of the software used to generate the index files can be found in the config.yaml file. Sometimes index files are not backwards-compatible, meaning index files generated by a newer version of a tool cannot be used by an older version of the tool. cat /varidata/research/projects/bbc/versioned_references/2023-05-03_15.28.41_v12/bin/config.yaml ## # This is the directory that the rsync rule will use as the source directory. It shuold be the run directory this workflow. ## sourceDir: &quot;/varidata/research/projects/bbc/research/prep_bbc_shared_current&quot; ## ## # This is where the timestamped directories and the &#39;latest&#39; symlink will be created. ## timestamp_dir: &quot;/varidata/research/projects/bbc/versioned_references/&quot; ## ## # Environment modules used. ## # Specify all environment modules here instead of within the Snakefile itself to make it easy to look over quickly. ## # When aligning using the index files created by this workflow, use the same version aligner as listed here to ensure compatibility. ## samtools: &quot;bbc/samtools/samtools-1.9&quot; ## picard: &quot;bbc/picard/picard-2.21.4-SNAPSHOT&quot; ## STAR: &quot;bbc/STAR/STAR-2.7.8a&quot; ## biscuit: &quot;bbc/biscuit/biscuit_1_0_1&quot; ## bwa: &quot;bbc/bwa/bwa-0.7.17&quot; ## bowtie2: &quot;bbc/bowtie2/bowtie2-2.4.1&quot; ## python3: &quot;bbc/python3/python-3.8.1&quot; ## bismark: &quot;bbc/bismark/bismark-0.23.0&quot; ## kb-python: &quot;bbc/kb-python/kb-python-0.24.4&quot; ## parallel: &quot;bbc/parallel/parallel-20191122&quot; ## gsutil: &quot;bbc/gsutil/gsutil-4.52&quot; ## seqtk: &quot;bbc/seqtk/seqtk-1.3-r115-dirty&quot; ## salmon: &quot;bbc/salmon/salmon-1.4.0&quot; ## kallisto: &quot;bbc/kallisto/kallisto-0.46.1&quot; 4.2 Symlink pre-run results to your directory Because the workflow will take a while (up to several hours) to run, we have run the workflow for you beforehand so that you don’t have to wait for your workflow to finish running. First, go to the base level of your “” directory. cd /varidata/researchtemp/hpctmp/BBC_workshop_Oct2024_III/&lt;username&gt; Then create the symlink. ln -s ../kin.lau/rnaseq_workflow/ . 4.3 Quality control It’s important to look through QC metrics to ensure that the data is likely to produce meaningful results. Ideally, you don’t want to waste time trying to interpret bad data. 4.3.1 multiQC report Use the OnDemand file explorer to download and open /varidata/researchtemp/hpctmp/BBC_workshop_Oct2024_III/&lt;username&gt;/rnaseq_workflow/results/multiqc/multiqc_report.html. Remember that within the OnDemand file explorer, you can click ‘Change directory’ to navigate directly to the enclosing directory. Alignment rate? Higher duplication rate can be normal for RNA-seq. Strandedness; In our workflow, this is automatically inferred using Salmon. Any contamination? Check FastqScreen results. 4.3.2 Other considerations Not a bad idea to look quickly at the alignments in IGV. Any sign of gDNA contamination? Mutations in specific genotypes? Is it exonic? Can do a quick check in IGV. How many genes expressed? Easy to check in R. Marker genes? Can do a quick check in iSEE if you expect certain expression patterns between groups. Any genes supposed to knocked out or knocked down? Use iSEE. Does the PCA show clustering? Use iSEE. 4.4 DE analysis using R and DESeq2 4.4.1 Create an R project Please go to VAI OnDemand. Click on RStudio Server, and create a new RStudio session. Please make sure you are loading the correct R module for this workshop, bbc2/R/alt/R-4.4.0-setR_LIBS_USER, which you can select from the drop down menu. Type “short” in the “Partition” field (if you encounter issues, you can also try “long”). Set CPU as 1, memory as 16GB, and time as 6 hours. Click “Launch”. In the Rstudio window, click “File” in the upper left corner, click on “New Project” &gt; “New Directory” &gt; “New Project”. Then, click on “Browse…”, you can click on triple dot horizontal button and type /varidata/researchtemp/hpctmp/BBC_workshop_Oct2024_III/&lt;username&gt;. Click “choose”. Next, you will go back to the project wizard, and type “workshop_2024” in the “Directory name” field. Click “Create Project”. You will be the newly created “workshop_2024” folder, which will contain a new file named “workshop_2024.Rproj”, which Rstudio uses to store details about your R project. 4.4.1.1 Why create R projects? Creating an R Project in RStudio is recommended for several reasons: A R Project creates a dedicated working directory for your project files, including R scripts, data files, figures, and output. This helps in organizing your files that are related to a specific project. Automatic working directory setup. When you open an R Project, RStudio automatically sets the working directory to the project folder. Reproducibility. With a project-based setup, the code and files related to a project stay together, making it easier to reproduce results. Version control integration and package development support. 4.4.2 Exploring the data using iSEE The iSEE app allows us to explore our data interactively, making changes on-the-fly. It is more convenient to mount the HPC storage to your computer and run iSEE locally, but for simplicity we will follow the steps below to run iSEE via OnDemand Rstudio. Go to the terminal. Go to your newly created workshop_2024 R project directory, then copy app.R and sce.rds from rnaseq_workflow/iSEE/ to there. cd /varidata/researchtemp/hpctmp/BBC_workshop_Oct2024_III/&lt;username&gt;/workshop_2024 cp ../rnaseq_workflow/iSEE/* . To run the iSEE app, go back to OnDemand Rstudio, open the app.R file and click “Source”. iSEE screenshot. 4.4.3 Make a separate folder for DE analysis and a script file to store our commands We will create a new folder for the differential expression analysis of this workshop. Click “New Folder” and enter “DE_genes” for the folder name. Create an R script file to record the code that you will use for this part of the workshop today. Click on the “DE_genes” folder to enter it. Click “New Blank File” &gt; “R script”. Type in “deseq2.R” for the filename and click “OK”. Unless otherwise noted, run all following code by copying and pasting into “deseq2.R” then highlighting the commands you want to run and typing either Cmd + Enter (Mac) or Ctrl + Enter (Windows). 4.4.4 Make an output directory To ensure it is clear which files are produced by a given script, it is good practice to make a unique folder for storing each script’s output. outdir &lt;- &quot;./DE_genes/deseq2_out_files/&quot; dir.create(outdir, recursive=TRUE) 4.4.5 Install packages For this workshop, we ran the Rstudio job with the bbc2/R/alt/R-4.4.0-setR_LIBS_USER module. This allows you to use R packages that we have installed beforehand. For your actual work, we encourage you to run Rstudio jobs with the bbc2/R/R-4.4.0 module which will allows you to make and maintain your own R package library, avoiding permission issues when updating packages or installing new ones. While CRAN packages can be installed with install.packages(), Bioconductor packages have to be installed with the install() function in the BiocManager package. # AS EXPLAINED ABOVE, NO NEED TO RUN THESE FOR THE WORKSHOP # if (!require(&quot;BiocManager&quot;, quietly = TRUE)) # install.packages(&quot;BiocManager&quot;) # # BiocManager::install(c(&quot;dplyr&quot;,&quot;stringr&quot;,&quot;ggplot2&quot;,&quot;readr&quot;,&quot;ggrepel&quot;,&quot;ComplexHeatmap&quot;,&quot;DESeq2&quot;,&quot;iSEE&quot;)) 4.4.6 Load packages In order to let R know where to look for the functions we will use, we need to load them using the library() function. The suppressPackageStartupMessages() function calls here are simply to mute the automatic start-up messages of some of these packages to avoid cluttering what we are looking at. suppressPackageStartupMessages(library(dplyr)) library(stringr) library(ggplot2) library(readr) library(ggrepel) suppressPackageStartupMessages(library(ComplexHeatmap)) suppressPackageStartupMessages(library(DESeq2)) 4.4.7 Set up your DESeq object The BBC Snakemake workflow collates all the gene counts into an R object saved in the results/SummarizedExperiment/SummarizedExperiment.rds file. The readRDS function loads that object into our environment. se &lt;- readRDS(&quot;../rnaseq_workflow/results/SummarizedExperiment/SummarizedExperiment.rds&quot;) # What is type of object is this? class(se) 4.4.8 What is a SummarizedExperiment object? A SummarizedExperiment object allows us to store and manipulate sample meta data, gene meta data and gene counts in separate, coordinated dataframes and matrices. Subsetting and reordering samples or genes can be done using the familiar object[row, column] R syntax, where the genes are the rows and the samples are the columns (object[genes, samples]). Later on, we will go through some exercises to further demonstrate the usefulness of “SummarizedExperiment” objects. SummarizedExperiment Let’s take a look to see what assays are stored in the SummarizedExperiment object. Note that DESeq2 requires the first assay to be named “counts” and assumes it contains the raw counts. assayNames(se) ## [1] &quot;counts&quot; &quot;tpms&quot; &quot;vst&quot; stopifnot(assayNames(se)[1] == &quot;counts&quot;) Let’s take a look at the sample meta data in the “se” object. The BBC snakemake workflow automatically adds the samplesheet metadata into the “se” object. colData(se) ## DataFrame with 8 rows and 3 columns ## sample group RG ## &lt;character&gt; &lt;character&gt; &lt;logical&gt; ## SRR1039508 SRR1039508 trt NA ## SRR1039512 SRR1039512 trt NA ## SRR1039516 SRR1039516 trt NA ## SRR1039520 SRR1039520 trt NA ## SRR1039509 SRR1039509 untrt NA ## SRR1039513 SRR1039513 untrt NA ## SRR1039517 SRR1039517 untrt NA ## SRR1039521 SRR1039521 untrt NA Similarly, the gene meta data can be used to store alternate gene names. These will come in handy for downstream visualizations or pathway analyses. rowData(se) ## DataFrame with 60721 rows and 4 columns ## Symbol Uniq_syms entrez ## &lt;character&gt; &lt;character&gt; &lt;character&gt; ## ENSG00000223972.5 NA ENSG00000223972.5 NA ## ENSG00000227232.5 NA ENSG00000227232.5 NA ## ENSG00000278267.1 MIR6859-2 MIR6859-2_ENSG000002.. 102465909 ## ENSG00000243485.5 NA ENSG00000243485.5 NA ## ENSG00000284332.1 MIR1302-2 MIR1302-2 100302278 ## ... ... ... ... ## ENSG00000276017.1 NA ENSG00000276017.1 NA ## ENSG00000278817.1 DGCR6 DGCR6_ENSG0000027881.. 8214 ## ENSG00000277196.4 PRODH PRODH_ENSG0000027719.. 5625 ## ENSG00000278625.1 LOC124905334 LOC124905334 124905334 ## ENSG00000277374.1 NA ENSG00000277374.1 NA ## Gene_name ## &lt;character&gt; ## ENSG00000223972.5 NA ## ENSG00000227232.5 NA ## ENSG00000278267.1 microRNA 6859-2 ## ENSG00000243485.5 NA ## ENSG00000284332.1 microRNA 1302-2 ## ... ... ## ENSG00000276017.1 NA ## ENSG00000278817.1 DiGeorge syndrome cr.. ## ENSG00000277196.4 proline dehydrogenas.. ## ENSG00000278625.1 U6 spliceosomal RNA ## ENSG00000277374.1 NA The counts and the meta data need to be stored inside a DESeq2 object called a ‘DESeqDataSet’, which is also a ‘SummarizedExperiment’ so ‘SummarizedExperiment’ functions will work on it. We specify that each gene will be fit with a model design of ‘~ group’. dds &lt;- DESeqDataSet(se, design = ~ group) ## converting counts to integer mode ## Warning in DESeqDataSet(se, design = ~group): some variables in design formula ## are characters, converting to factors 4.4.9 Remove genes with low/no expression We cannot do meaningful analyses of genes with very low counts. This will also speed up the analysis. # prefilter genes, keeping only genes with 10 or more total read counts across samples keep &lt;- rowSums(counts(dds)) &gt;= 10 # counts() is the same as assay(dds, &quot;counts&quot;) message(str_glue(&quot;Keeping {sum(keep)} genes.&quot;)) ## Keeping 21485 genes. dds &lt;- dds[keep, ] 4.4.10 Different normalization approaches for different biases Types of biases in RNA-seq 4.4.11 Run the DE workflow The DESeq function is a convenience function from DESeq2 that estimates size factors (normalization) and fits negative binomial GLMs. dds &lt;- DESeq(dds) ## estimating size factors ## estimating dispersions ## gene-wise dispersion estimates ## mean-dispersion relationship ## final dispersion estimates ## fitting model and testing message(paste0(&quot;Coefficient names are: &quot;, paste(resultsNames(dds), collapse = &quot; &quot;))) ## Coefficient names are: Intercept group_untrt_vs_trt After the models are fitted, we can test specific pairs of groups for differential expression. For DESeq2, it is recommended to provide the significance cutoff that you wish to use as it affects the multiple testing correction procedure (see docs). Here we specify a significance cutoff of 0.05. contrast &lt;- c(&quot;group&quot;, &quot;trt&quot;, &quot;untrt&quot;) fdr_cutoff &lt;- 0.05 res &lt;- results(dds, contrast=contrast, alpha=fdr_cutoff) res &lt;- res[order(res$pvalue), ] 4.4.12 Summarize DE results Let’s see how many genes were significantly up or down regulated. df &lt;- as.data.frame(res) data.frame( UP=sum(df$padj &lt;= fdr_cutoff &amp; df$log2FoldChange &gt; 0, na.rm = TRUE), DWN=sum(df$padj &lt;= fdr_cutoff &amp; df$log2FoldChange &lt; 0, na.rm = TRUE), Tested=sum(!is.na(df$padj)) ) ## UP DWN Tested ## 1 1158 1534 18105 4.4.13 P value distribution Ideally, we will see an anti-conservative (if there are many DE genes) or uniform pattern (not many DE genes). See here for more details about how to interpret these. ggplot(data = df %&gt;% dplyr::filter(!is.na(pvalue)), aes(x = pvalue)) + geom_histogram(color = &quot;black&quot;, fill = &quot;gray55&quot;, breaks = seq(0, 1, 0.05)) + theme_bw() + theme(plot.title=element_text(size=10)) 4.4.14 Shrink log fold changes for lowly expressed genes This step does not affect which genes are statistically DE, but we perform this to obtain more reliable estimates of the log fold changes for visualizations or for ranking genes (e.g. GSEA). lfc_shrink &lt;- lfcShrink(dds, contrast=contrast, type=&quot;ashr&quot;) ## using &#39;ashr&#39; for LFC shrinkage. If used in published research, please cite: ## Stephens, M. (2016) False discovery rates: a new deal. Biostatistics, 18:2. ## https://doi.org/10.1093/biostatistics/kxw041 lfc_shrink &lt;- lfc_shrink[order(lfc_shrink$pvalue), ] Let’s visualize the effect of shrinking the LFCs using MA plots. DESeq2::plotMA(res, main=&quot;Default LFC&quot;) DESeq2::plotMA(lfc_shrink, main=&quot;Shrunken LFC&quot;) 4.4.15 Output DE results Here, we merge the different gene name columns to the DE results and output to a tab-delimited file, which can be opened in Excel for manual perusal. NOTE: You will use this file for the next section of the workshop about pathway analysis. df &lt;- cbind(as.data.frame(rowData(dds)[rownames(lfc_shrink), 1:4]), as.data.frame(lfc_shrink)) %&gt;% tibble::rownames_to_column(&quot;ens_gene&quot;) write_tsv(df, file.path(outdir, &quot;de_res.tsv&quot;)) 4.4.16 Output tables with log2 normalized counts For the log2 normalized counts, we commonly use the variance stabilized transformation (VST). These values can be used for heatmaps, clustering or other downstream applications. vsd &lt;- vst(dds, blind=FALSE) vst_df &lt;- as.data.frame(cbind(rowData(vsd)[, 1:4], assay(vsd))) %&gt;% tibble::rownames_to_column(&quot;ens_gene&quot;) write_tsv(vst_df, file.path(outdir, &quot;vst.tsv&quot;)) 4.4.17 Why should we transform counts for visualizations or clustering? Biological factors can increase gene count variation, but this can be muddied by dependence of the variance on the magnitude of the mean. Below, we can visualize how different transformations impact the mean-variance relationship. Here we also reiterate that these transformations are only for analyses downstream of DE analysis; the statistical framework in DESeq2 (and edgeR) is designed to work with raw counts. library(vsn) library(patchwork) ntd &lt;- normTransform(dds) # log2(n + 1) gg1 &lt;- meanSdPlot(counts(dds), plot=FALSE)[[&quot;gg&quot;]] + ggtitle(&quot;Raw counts&quot;) gg2 &lt;- meanSdPlot(assay(ntd), plot=FALSE)[[&quot;gg&quot;]] + ggtitle(&quot;log2(n+1)&quot;) gg3 &lt;- meanSdPlot(assay(vsd), plot=FALSE)[[&quot;gg&quot;]] + ggtitle(&quot;Variance stabilizing transformed&quot;) # use patchwork to combine the three plots into one figure. (gg1 | gg2 | gg3) + plot_layout(nrow = 1) 4.5 Volcano plot First, run the code below which makes a new function to make a volcano plot. make_volcano &lt;- function(df, pval_nm, pval_cutoff=0.1){ # remove genes with NA for pvalue df &lt;- df[which(!is.na(df[[pval_nm]])), ] # add gene names df &lt;- cbind(df, rowData(dds)[rownames(df), 1:4]) top_genes &lt;- df %&gt;% dplyr::arrange(desc(abs(df$log2FoldChange))) %&gt;% dplyr::filter(row_number() &lt;= 10) %&gt;% rownames() df$Sig &lt;- ifelse(df$padj &lt;= pval_cutoff, &quot;Sig&quot;, &quot;NS&quot;) df[[pval_nm]] &lt;- -log10(df[[pval_nm]]) ggplot(df, aes(x=.data[[&quot;log2FoldChange&quot;]], y=.data[[pval_nm]])) + geom_point(aes(color=Sig), size=0.6) + scale_color_manual(values=c(&quot;black&quot;, &quot;salmon&quot;)) + theme_bw() + ylab(str_glue(&quot;-log10(&quot;, pval_nm,&quot;)&quot;)) + geom_text_repel(data=df[top_genes, ], aes(label=Uniq_syms), max.overlaps=Inf, min.segment.length = 0) } Run the command below to use the above function to make a volcano plot. Functions can help reduce the amount of code we have to write if we have to run similar code multiple times; for example, if we had multiple groups in our experiment and wanted to make volcano plots for several different contrasts. make_volcano(as.data.frame(lfc_shrink), pval_nm=&quot;padj&quot;, pval_cutoff=fdr_cutoff) 4.6 Make a new SummarizedExperiment to store all results # recall that we removed some genes new little or no expression. se2 &lt;- se[rownames(dds), colnames(dds)] # replace the old variance-stabilized transformed counts stopifnot(identical(rownames(se2), rownames(vsd))) stopifnot(identical(colnames(se2), colnames(vsd))) assay(se2, &quot;vst&quot;) &lt;- assay(vsd) # Add DE results rowData(se2)$trt.v.untrt.pval &lt;- as.data.frame(lfc_shrink)[rownames(se2), &quot;pvalue&quot;] rowData(se2)$trt.v.untrt.padj &lt;- as.data.frame(lfc_shrink)[rownames(se2), &quot;padj&quot;] rowData(se2)$trt.v.untrt.lfc &lt;- as.data.frame(lfc_shrink)[rownames(se2), &quot;log2FoldChange&quot;] rowData(se2) ## DataFrame with 21485 rows and 7 columns ## Symbol Uniq_syms entrez ## &lt;character&gt; &lt;character&gt; &lt;character&gt; ## ENSG00000227232.5 NA ENSG00000227232.5 NA ## ENSG00000278267.1 MIR6859-2 MIR6859-2_ENSG000002.. 102465909 ## ENSG00000241860.7 NA ENSG00000241860.7 NA ## ENSG00000279457.4 NA ENSG00000279457.4 NA ## ENSG00000228463.10 RPL23AP21 RPL23AP21 728481 ## ... ... ... ... ## ENSG00000273748.1 NA ENSG00000273748.1 NA ## ENSG00000271254.6 LOC102724250 LOC102724250 102724250 ## ENSG00000278673.1 NA ENSG00000278673.1 NA ## ENSG00000278817.1 DGCR6 DGCR6_ENSG0000027881.. 8214 ## ENSG00000277196.4 PRODH PRODH_ENSG0000027719.. 5625 ## Gene_name trt.v.untrt.pval trt.v.untrt.padj ## &lt;character&gt; &lt;numeric&gt; &lt;numeric&gt; ## ENSG00000227232.5 NA 0.699875 0.88721 ## ENSG00000278267.1 microRNA 6859-2 0.941844 NA ## ENSG00000241860.7 NA 0.488979 NA ## ENSG00000279457.4 NA 0.650232 0.86135 ## ENSG00000228463.10 ribosomal protein L2.. 0.446495 NA ## ... ... ... ... ## ENSG00000273748.1 NA 6.98054e-01 0.886856022 ## ENSG00000271254.6 neuroblastoma breakp.. 9.71630e-05 0.001446724 ## ENSG00000278673.1 NA 9.47906e-01 NA ## ENSG00000278817.1 DiGeorge syndrome cr.. 3.02400e-02 NA ## ENSG00000277196.4 proline dehydrogenas.. 1.47224e-05 0.000285074 ## trt.v.untrt.lfc ## &lt;numeric&gt; ## ENSG00000227232.5 0.03692037 ## ENSG00000278267.1 0.00642251 ## ENSG00000241860.7 0.06385483 ## ENSG00000279457.4 0.04216935 ## ENSG00000228463.10 0.07241761 ## ... ... ## ENSG00000273748.1 -0.03748339 ## ENSG00000271254.6 0.66240874 ## ENSG00000278673.1 -0.00502522 ## ENSG00000278817.1 -0.28581346 ## ENSG00000277196.4 -2.92428962 4.7 Heatmap of top DE genes make_ht &lt;- function(se, genes, assay_nm=&quot;vst&quot;, col_annot = &quot;group&quot;, row_label = &quot;Uniq_syms&quot;){ ht_se &lt;- se[genes, ] coldat &lt;- as.data.frame(colData(ht_se)[, col_annot, drop=FALSE]) coldat_lvls &lt;- unique(coldat[, 1]) ht_col_colors &lt;- list(setNames(nm=coldat_lvls, object = viridis::viridis(length(coldat_lvls)))) names(ht_col_colors) &lt;- col_annot Heatmap(t(scale(t(assay(ht_se, assay_nm)), scale=FALSE, center = TRUE)), name = &quot;Mean-centered\\nexpression&quot;, cluster_columns = FALSE, row_labels=rowData(ht_se)[, row_label], show_column_names = TRUE, top_annotation=HeatmapAnnotation(df=coldat, col=ht_col_colors), row_title = paste0(nrow(ht_se), &quot; genes&quot;) ) } # sort genes in the se object based on significance. se2 &lt;- se2[order(rowData(se2)$trt.v.untrt.pval), ] top_genes &lt;- rownames(se2)[1:20] make_ht(se=se2, genes=top_genes, assay_nm=&quot;vst&quot;, col_annot = &quot;group&quot;) 4.8 Look for specific genes We know certain genes should be differentially expressed based on the paper that this dataset came from. We can check that these genes were significantly DE in our analysis. gois &lt;- c(&quot;DUSP1&quot;, &quot;KLF15&quot;, &quot;CRISPLD2&quot;) # we need to convert these to ensembl IDs gois &lt;- rownames(se2)[match(gois, rowData(se2)[, &quot;Symbol&quot;])] make_ht(se=se2, genes=gois, assay_nm=&quot;vst&quot;, col_annot = &quot;group&quot;) 4.9 SummarizedExperiment exercises 4.10 Your turn Copy ‘se2’ to make a new object. Filter for significance then rank by the absolute value of LFC, largest to smallest. Reorder the samples in the new object so that ‘untrt’ samples are on the left in the heatmap. Plot top DEGs heatmap based on LFC ranking. Click here to see an example solution se3 &lt;- se2 se3 &lt;- se3[which(rowData(se3)$trt.v.untrt.padj &lt;= 0.05), ] # note that some rows have NAs in this column, so we use which() se3 &lt;- se3[order(abs(rowData(se3)$trt.v.untrt.lfc), decreasing = TRUE), ] se3 &lt;- se3[, rev(order(se3$group))] top_genes &lt;- rownames(se3)[1:30] make_ht(se=se3, genes=top_genes, assay_nm=&quot;vst&quot;, col_annot = &quot;group&quot;) 4.11 Venn diagrams One option is ggVennDiagram. 4.12 Upset plots We recommend using the ComplexHeatmap package. "],["pathway-and-enrichment-analysis.html", "Part 5 Pathway and enrichment analysis 5.1 Downstream of DE gene analysis 5.2 Why enrichment and pathway analysis? 5.3 ORA 5.4 GSEA 5.5 Other R packages and tools", " Part 5 Pathway and enrichment analysis 5.1 Downstream of DE gene analysis It is likely that you have a R object created for DE gene analysis, we will be loading DE gene results and conduct enrichment analyses. We will create a new R script called enrichment_script, under a new folder pathways: Click “Files”, “New Folder” and enter “pathways” for the folder name. Create an R script file to record the code that you will use for enrichment analysis: click “File” &gt; “New File” &gt; “R script”. Click “File” &gt; “Save”; save the file as “enrichment_script.R” under “pathway” (you might have to click pathway folder icon) 5.1.1 load packages suppressPackageStartupMessages({ library(DESeq2) library(ggrepel) library(clusterProfiler) library(tidyverse) library(enrichplot) library(org.Hs.eg.db) library(pathview) }) 5.1.2 Import previous DE results Create a output dir first, then read the DE gene results. outdir &lt;- &quot;./enrichment_res/&quot; dir.create(outdir, recursive=TRUE) de_res &lt;- read_tsv(&quot;DE_genes/deseq2_out_files/de_res.tsv&quot;) 5.1.3 How many DE genes ## note the part after the &quot;.&quot; sign is the version number, here we can just remove it. de_res$ens_gene &lt;- str_split_fixed(de_res$ens_gene, &quot;\\\\.&quot;, 2)[, 1] ## check the first a few rows again head(de_res) ## # A tibble: 6 × 10 ## ens_gene Symbol Uniq_syms entrez Gene_name baseMean log2FoldChange lfcSE ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 ENSG00000152… SPARC… SPARCL1 8404 SPARC li… 994. -4.54 0.210 ## 2 ENSG00000148… STOM STOM 2040 stomatin 13368. -1.41 0.0881 ## 3 ENSG00000179… PER1 PER1 5187 period c… 764. -3.13 0.204 ## 4 ENSG00000134… PHC2 PHC2 1912 polyhome… 2708. -1.37 0.0902 ## 5 ENSG00000120… DUSP1 DUSP1 1843 dual spe… 3357. -2.90 0.198 ## 6 ENSG00000125… MT2A MT2A 4502 metallot… 3627. -2.17 0.150 ## # ℹ 2 more variables: pvalue &lt;dbl&gt;, padj &lt;dbl&gt; fdr_cutoff &lt;- 0.1 up_reg_genes &lt;- de_res |&gt; filter(padj &lt; fdr_cutoff &amp; log2FoldChange &gt; 0 ) down_reg_genes &lt;- de_res |&gt; filter(padj &lt; fdr_cutoff &amp; log2FoldChange &lt; 0 ) message(&quot;Number of up-regulated genes is: &quot;, nrow(up_reg_genes)) ## Number of up-regulated genes is: 1481 message(&quot;Number of down-regulated genes is: &quot;, nrow(down_reg_genes)) ## Number of down-regulated genes is: 1872 5.2 Why enrichment and pathway analysis? It can be difficult to look at so many genes, and sometimes a list of genes do not provide any biological insights. Enrichment and pathway analyses are performed to determine if there is any known biological functions, interactions or pathways in your DE gene studies. Generally speaking, Enrichment and pathway analyses are not restricted for DE gene expression, they can be performed on proteomics data, ChIP-seq, and genomic data as well. There are different algorithms for enrichment and pathway analyses. In this session, we will focus on two types: ORA (over representation analysis) and GSEA (gene set enrichment analysis). 5.3 ORA ORA explores whether there is enrichment of known biological functions or pathways in a particular set of genes (e.g. significantly up- or down-regulated genes). Gene ontology (GO) and KEGG (Kyoto Encyclopedia of Genes and Genomes) are two broadly used databases that are curated for exploring pathways and gene functions. GO is a framework used to represent and categorize gene functions across different species in a standardized manner. It provides a controlled vocabulary that describes genes in terms of their associated biological processes, cellular components, and molecular functions. The Gene Ontology Consortium maintains the GO vocabulary, as known as GO terms. Click to expand More details on GO terms: To describe the roles of genes and gene products, GO terms are organized into three independent components in a species-independent manner: Biological process: refers to the biological role involving the gene or gene product, and could include “transcription”, “signal transduction”, and “apoptosis”. Molecular function: represents the biochemical activity of the gene product, such activities could include “ligand”, “protein binding”, and “enzyme activity”. Cellular component: refers to the location in the cell of the gene product, such as “lysosome” and “plasma membrane”. The GO terms are loosely hierarchical, ranging from general, ‘parent’, terms to more specific, ‘child’ terms. In this session, we will be mostly using clusterProfiler to conduct enrichment analyses. In the ORA here, we will be testing whether 2 fold up-regulated (logfold-change = 1, as log fold change is often log2 based) genes are enriched in which GO terms. We will be using enrichGO function from clusterProfiler, and use the whole dataset (~20,000 genes) as the background (universe in enrichGO function). ## only getting DE genes at least have 2 fold change, so log2FC &gt; 1, only up-regulated genes. genes_2f_up &lt;- de_res |&gt; filter(padj &lt; fdr_cutoff &amp; log2FoldChange &gt; 1) message(&quot;Number of DE genes have at least 2 fold change is: &quot;, nrow(genes_2f_up)) ## Number of DE genes have at least 2 fold change is: 246 ego_BP &lt;- enrichGO(gene = as.character(genes_2f_up$entrez), universe = as.character(de_res$entrez), OrgDb = org.Hs.eg.db, ont = &quot;BP&quot;, pAdjustMethod = &quot;BH&quot;, qvalueCutoff = 0.05, keyType = &quot;ENTREZID&quot;, readable = TRUE) 5.3.1 plot ORA results Dotplots can be used to depict the enrichment scores (e.g. p values) and gene count or ratio as circle size and colors. Cneplots, gene-concept network, allows us to know which genes are involved in these significant GO terms or pathways, as well as the linkages among GO terms or pathways. dotplot(ego_BP, showCategory = 20, font.size = 9 ) + ggtitle(&quot;dotplot for ORA - BP&quot;) cnetplot(ego_BP, showCategory = 10, node_label_size = 0.6, cex_label_category = 0.8, cex_label_gene = 0.5, cex_category = 0.8, cex_genes = 0.5, max.overlaps = Inf) + ggtitle(&quot;Gene-concept network for ORA - GO:BP&quot;) 5.3.2 save ORA results to a tsv file You can easily load this into Excel ego_BP_df &lt;- ego_BP |&gt; as.data.frame() ## output the BP enrichment results into a tsv file write_tsv(ego_BP_df, paste0(outdir, &quot;/clusterProfiler_BP_res.tsv&quot;)) Click to expand Exercise on your own: Try to rerun the analyses: Using the same conditions, return the enriched GO processes for the Molecular Function ontology. How would the enrichGO() function change if our organism was mouse? 5.4 GSEA ORA is based on these differentially expressed genes. This approach will find genes where the difference is large and will fail where the difference is small, but evidenced in coordinated way in a set of related genes. GSEA directly addresses this limitation. Unlike ORA where an arbitrary threshold is set as “significant DE genes”, all genes can be used in GSEA. We usually sort genes based on their fold changes or p-values, and compare this sorted gene list to a predefined gene set, such as genes in certain pathways. It will help to detect situations where all genes in a predefined set change in a small but coordinated manner. P-values are generated through permutation tests. This type of analysis can be particularly helpful if the differential expression analysis only outputs a small number of significant DE genes. Here, what we create is a sorted list of all genes (~20,000 genes) in our dataset sorted by -log10(pvalue) and sign of fold change; this way, up-regulated and down-regulated genes will be at the top and bottom of the list. In GSEA, we will show how to run GSEA on KEGG pathways ## we will use all the genes. Get the fold change and pvalues. gene_list &lt;- sign(de_res$log2FoldChange) * -log10(de_res$pvalue) ## or we can just use fold change data. ## get the name of the genes. names(gene_list) &lt;- de_res$entrez ## the names of the gene list is the en ID. ## remove NA is there is any in the fold change or gene names if(any(is.na(gene_list))){ gene_list = gene_list[-which(is.na(gene_list))] } if(any(is.na(names(gene_list)))) { gene_list = gene_list[-which(is.na(names(gene_list)))] } ## also remove duplicated gene names gene_list &lt;- gene_list[!duplicated(names(gene_list))] ## sort from largest to smallest. gene_list &lt;- sort(gene_list, decreasing = TRUE) head(gene_list) ## 115207 6536 9181 165215 338382 1277 ## 43.56579 42.34242 32.18764 31.64835 29.16647 28.73637 # set seeds set.seed(1234) ## run GSEA using clusterProfiler gseaKEGG &lt;- gseKEGG(geneList = gene_list, # ordered named vector of fold changes (Entrez IDs are the associated names) organism = &quot;hsa&quot;, nPerm = 1000, # default number permutations minGSSize = 100, # minimum gene set size (# genes in set) - change to test more sets or recover sets with fewer # genes pvalueCutoff = Inf, # padj cutoff value verbose = FALSE, eps = 0) ## Reading KEGG annotation online: &quot;https://rest.kegg.jp/link/hsa/pathway&quot;... ## Reading KEGG annotation online: &quot;https://rest.kegg.jp/list/pathway/hsa&quot;... gseaKEGG_gene_symbol &lt;- setReadable(gseaKEGG, &#39;org.Hs.eg.db&#39;, &#39;ENTREZID&#39;) 5.4.1 save gsea results # gsea is a large list, and we convert it to a data frame, and save the results gsea_df &lt;- gseaKEGG_gene_symbol |&gt; as.data.frame() write_tsv(gsea_df, paste0(outdir, &quot;/clusterProfiler_KEGG_GSEA_res.tsv&quot;)) 5.4.2 plot GSEA results Similarity, we can make dotplot and gene-concept network plots here. # first dotplot dotplot(gseaKEGG_gene_symbol, showCategory = 15) + ggtitle(&quot;dotplot for gsea - KEGG pathways&quot;) cnetplot(gseaKEGG_gene_symbol, showCategory = 5, node_label_size = 0.6, cex_label_category = 0.8, cex_label_gene = 0.5, cex_category = 0.8, cex_genes = 0.5, max.overlaps = Inf) + ggtitle(&quot;Gene-concept network for gsea-KEGG pathways&quot;) # Specific plots we can make for GSEA results gseaplot(gseaKEGG_gene_symbol, geneSetID = &#39;hsa04910&#39;) 5.4.3 plot KEGG map # Lastly, we can map gene expression to a KEGG map foldchanges &lt;- de_res$log2FoldChange names(foldchanges) &lt;- de_res$entrez pathview(gene.data = foldchanges, pathway.id = &#39;hsa04910&#39;, species = &quot;hsa&quot;, limit = list(gene = 2, # value gives the max/min limit for foldchanges cpd = 1), low=list(gene=&quot;steelblue&quot;), high=list(gene=&quot;gold&quot;)) ## you can download the map from Rstudio, and you will be seeing something like this. Example pathview output. 5.5 Other R packages and tools We introduced a few commonly used R packages to conduct enrichment and pathway analyses. Other popular tools and R packages include: - g:Profiler: a web based toolfor functional profiling of gene or protein lists. - gprofiler2, an R interface (package) to the widely used web toolset g:Profiler. - Revigo: if you have a long list Gene Ontology terms, Revigo can nd summarize them by removing redundant GO terms. - aPear: generate an enrichment network from enrichment results, works seamlessly with clusterProfiler. - cytospace: an open source software platform for visualizing complex networks. Cytospace offer many apps (formerly known as plugins) to extends its functionalities, and see here for a workflow of how to visualize omics data using Cytospace and its apps. "],["appendices.html", "Part 6 Appendices 6.1 Other workshop files 6.2 Local access of files on the HPC 6.3 Bash cheatsheet", " Part 6 Appendices 6.1 Other workshop files First workshop material 6.2 Local access of files on the HPC Mac: 1. Click Finder &gt; “Go” in task bar &gt; “Connect to Server” in the pulldown menu. 2. Type smb://pn.vai.org and click “Connect”. 3. Select ‘projects’ and ‘researchtemp’. Click “OK”. 4. You can now navigate using Finder, or type ls /Volumes/projects/ or ls /Volumes/researchtemp/ in the Terminal. Windows: * In File Explorer, type \\\\pn.vai.org\\ and hit Enter. 6.3 Bash cheatsheet Name Command Line Description Example Print Working Directory pwd Displays the current working directory [username\\@submit002 ~]$ pwd Result:/home/username List ls Lists the files and directories in the current directory [username\\@submit002 ~]$ ls Result: It returns empty after the $ symbol since nothing has been created. List More Detail ls -lht Display more details about the file [username\\@submit002 ~]$ ls -lht Result: Display file detail in the current director Make Directory mkdir Creates a new directory [username\\@submit002 ~]$ mkdir hpc_mini_workshop Result: A hpc_mini_workshop folder is created. Move mv Moves or renames files or directories [username\\@submit002 ~]$ mv hpc_mini_workshop workshopTraining Result: Now the hpc_mini_workshop directory is called workshopTraining Change Directory cd Change to an existing directory [username\\@submit002 ~]$ cd workshopTraining Result: [username@submit002 workshopTraining]$ Notice ~ was in the home directory, now in the workshopTraining directory. Remove rm Deletes files and directories [username\\@submit002 ~]$ rm -r TaskProject *Note: -r means directory Result: TaskProject is deleted Copy cp Copies files or directories [username\\@submit002 ~]$ cp -r Task1 Project Result: Task1 directory has moved to the Project directory. Search for File find Search for files and directories based on various criteria like name, size, and modification time [username\\@submit002 ~]$ find Project Result: Task1 will appear within the Project directory Project Project/Task1 Head head Display at the beginning of a file [username\\@submit002 ~]$ head -n5 file_name Result: It will display the first 5 lines from the beginning of the file_name. Tail tail Display at the end of a file [username\\@submit002 ~]$ tail -n5 file_name Result: It will display the last 5 lines from the end of the file_name Less less Load the necessary portion of a file [username\\@submit002 ~]$ less file.txt Result: The user is able to view a portion of the file.txt. More more Load the entire file [username\\@submit002 ~]$ more file.txt Result: The user is able to view the entire file.txt. Quit q Stop viewing the current file quit viewing the current file Concatenate cat Display the contents of a file [username\\@submit002 ~]$ cat file.txt Result: Display the contents of file.txt Search for Text grep Search for a specific pattern of text within files [username\\@submit002 ~]$ grep “GCGGA” sequence_file.fastq Result: Display any GCGGA pattern in sequence_file.fastq Word, Line, and Character Count wc Display the number of words, lines, and characters in a file [username\\@submit002 ~]$ wc file.txt Result: Display the number of words, lines, and characters in the file.txt. Touch touch Create a new empty file [username\\@submit002 ~]$ touch exampleFile.txt Result: The command line will display file details in the current directory "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
