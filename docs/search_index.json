[["index.html", "Basic command lines for HPC Part 1 Introduction", " Basic command lines for HPC The Bioinformatics and Biostatistics Core (BBC) Part 1 Introduction This book is divided into three sections: Basic command-line commands on the High-Performance Computing System (HPC). Performing a simple RNA-Seq analysis from read alignment to the identification of differentially expressed genes (DEGs). TBD "],["basic-command-lines-for-hpc.html", "Part 2 Basic command lines for HPC 2.1 Access HPC 2.2 File navigation 2.3 View and manipulate files 2.4 Exercise", " Part 2 Basic command lines for HPC 2.1 Access HPC Ensure that your laptop is connected to wifi “vai”, not “vai-guest”. 2.1.1 Mac users Open your terminal, and type ssh vai_username@access.hpc.vai.org, and enter your VAI password. 2.1.2 Windows user If MobaXterm is not installed, please download the free MobaXterm version, then set up, and agree with license agreements to proceed installation. Open MobaXterm Click on Session in the top left corner Click on SSH(Secure Shell) Enter access.hpc.vai.org in Remote host Click the little box on the left of Specify username, then type VAI username and enter VAI password Next, click OK 2.2 File navigation Practice directory: /varidata/researchtemp/hpctmp/BBC_workshop_June2023_I. 2.2.1 Navigate to a directory cd - change directory, navigate to a directory. Tip, ./ means current working directory. ../ means the parent directory. / is the root directory, ~ is home directory. Pay attention to these differences. pwd - displays the current working directory pwd cd /varidata/researchtemp/hpctmp/BBC_workshop_June2023_I pwd ## /varidata/research/projects/bbc/research/hpc_workshop_202209 ## /varidata/researchtemp/hpctmp/BBC_workshop_June2023_I 2.2.2 List content in a directory ls - list content; Without anything specified after ls, it will list the current directory. It can also list content of another directory. ls -lht – will show more details of content ls ls -lht ls -lht /varidata/researchtemp/hpctmp/BBC_workshop_June2023_I 2.2.3 Navigate to home directory Without anything after cd, you will change to your home directory, which is /home/username cd pwd 2.2.4 Create a directory mkdir dir_name - will create a directory “dir_name” in your current directory. You will be creating a directory in your home drectory. Make sure you are in your home directory first (use pwd), then create a directory called “hpc_workshop” pwd mkdir hpc_workshop 2.2.5 Copy a file cp - copy file/files Copy a file from /varidata/researchtemp/hpctmp/BBC_workshop_June2023_I to the directory you just created. pwd cp /varidata/researchtemp/hpctmp/BBC_workshop_June2023_I/test_01_R1.fq hpc_workshop ls hpc_workshop 2.3 View and manipulate files 2.3.1 Display content head - display as standard output (stdout) the first 10 lines/rows of the a file. tail - display as standard output (stdout) the last 10 lines/rows of the a file. You can use “-n” to control how many lines you want to see, default is 10 cd ~/hpc_workshop head test_01_R1.fq tail test_01_R1.fq head -2 test_01_R1.fq ## @A00426:207:H537LDMXY:1:1101:2067:1000 1:N:0:NCTAAGAT+NCGCGGTT ## NTAACAGTGACTTGCGGGGGAAGTCTACGCGCGTGTGCACGCGGCACTCTC ## + ## #FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF ## @A00426:207:H537LDMXY:1:1101:2139:1000 1:N:0:NCTAAGAT+NCGCGGTT ## NTGGCCATTCACAGTATGGTATTTCTGAATAACAATCTTATCCACAGAGTC ## + ## #FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF ## @A00426:207:H537LDMXY:1:1101:2230:1000 1:N:0:NCTAAGAT+NCGCGGTT ## NAGACTAATCATCAGATCTCCTCTCTCTATGCTACATCCACTCCATTCAA ## + ## FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF ## @A00426:207:H537LDMXY:1:1101:7148:1063 1:N:0:NCTAAGAT+NCGCGGTT ## TGGCCTTGCTCACAGAGCTGCGTGAGAAACAGACGGTGCTTGCGATCTCTG ## + ## FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF ## @A00426:207:H537LDMXY:1:1101:7256:1063 1:N:0:NCTAAGAT+NCGCGGTT ## GCACGGGCGAGGGCGGGAACGGCGGAGCGGGAAGAAGCCGCGAGCGCGGAT ## + ## FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF ## @A00426:207:H537LDMXY:1:1101:2067:1000 1:N:0:NCTAAGAT+NCGCGGTT ## NTAACAGTGACTTGCGGGGGAAGTCTACGCGCGTGTGCACGCGGCACTCTC 2.3.2 Pattern search grep - search a pattern by line grep &quot;AATTGG&quot; test_01_R1.fq ## NTCTGAATTGGGTTATGAGGCCCGGGAGGTGCCTCACCTCAGCCATTGAAC ## TGCCATTCTGTGCTCTCAGGACCTCTAATTGGGGGCCGTGGCAAAGGAGTG 2.3.3 Display the number of words, lines, and characters wc test_01_R1.fq wc -l test_01_R1.fq ## 1000 1250 42064 test_01_R1.fq ## 1000 test_01_R1.fq 2.3.4 List the content as stdout cat – list the contents of a file as stdout; cat (short for concatenate) is one of the most frequently used commands. To run this command, type cat followed by the file’s name: cat file.txt Combine two files: cat file1 file2. It is useful to pipe the content of the file into another command. 2.3.5 Pipe - redirection A pipe is a form of redirection (transfer of sdout to other destinations). You can send output from one command/program to another for further processing, such as command 1| command 2 | command 3. cat test_01_R1.fq | grep &quot;@&quot; | wc -l ## 250 2.4 Exercise Below we will copy another fowward reads into your home directory (~ means home directory), and combine them into one and count how many reads were there. You can direct the stdout of any command to a new file use &gt;. cd ~/hpc_workshop cp /varidata/researchtemp/hpctmp/BBC_workshop_June2023_I/test_54_R1.fq . cat test_01_R1.fq test_54_R1.fq | grep &quot;@&quot; | wc -l cat test_01_R1.fq test_54_R1.fq &gt; combined.fq ls ## 500 ## 01_linux_basics.Rmd ## 02_bioinfx_example.Rmd ## 03_rnaseq_workflow.Rmd ## 03_rnaseq_workflow_files ## 04_pathway_enrichment.Rmd ## 999_appendices.Rmd ## SummarizedExperiment.rds ## _bookdown.yml ## _bookdown_files ## _output.yml ## bbc_bioinfx_book.rds ## combined.fq ## docs ## fastqs ## full_fastqs ## img ## index.Rmd ## index.md ## multiqc ## packages.bib ## prep_render.sh ## render3bf38255731e8b.rds ## run_salmon.e ## run_salmon.o ## run_salmon.sh ## salmon ## test_01_R1.fq ## test_54_R1.fq ## toc.css "],["mini-project.html", "Part 3 Mini Project 3.1 Start an Interactive Job 3.2 Create Directory 3.3 Copy Fastq Files To fastqs subdirectory 3.4 Use basic Linux commands to explore the fastq files 3.5 Working With Environment Modules 3.6 Run FastQC 3.7 Set up a job script to run Salmon to align the reads 3.8 Submit a Job 3.9 Examine the Standard Output (stdout) and Standard Error (stderr) log files 3.10 Use grep to find the TPMs for a specific gene 3.11 BONUS: Use an interactive job to run multiQC on the Salmon and FastQC output", " Part 3 Mini Project Here, we will combine some of the commands we have learned today to perform a toy bioinformatic analysis. Two human paired-end samples (four total fastq files) have already been downloaded from GSE52778. To save time for the workshop, each file has been randomly subsetted to just a small fraction of the total reads. Here each user will: Copy these fastq files their own private project directory. Use basic Linux commands to learn some characteristics of these files. Use Salmon to align (pseudo-align) these reads to the hg38 reference transcriptome and get transcripts-per-million (TPMs) for each annotated gene. 3.1 Start an Interactive Job While simple file manipulations can be done on the submit node, computationally intensive operations should be performed using preallocated computational resources. An interactive job allows us to preallocate resources while still being able to run commands line by line. We will start an interactive job, requesting one CPU core and 6 hours of walltime. srun --nodes=1 --ntasks-per-node=1 --time=06:00:00 --pty bash After a job has been submitted, users can check on the status (e.g. how long it has been running) of it using the following. squeue -u &lt;username&gt; 3.2 Create Directory Typically, one would work in their specific lab’s folder on the HPC. For this workshop, we will work in a common directory so that the instructors and chck on your progress. cd /varidata/researchtemp/hpctmp/BBC_workshop_June2023 Create a directory based on your username to separate your work from other users’. mkdir &lt;username&gt; Navigate to the username directory cd &lt;username&gt; Create a fastqs directory inside the username directory. It is good practice to keep your raw data separate from your analyses and never make changes to them directly. mkdir fastqs Use ls to confirm the fastqs directory was created. ls 3.3 Copy Fastq Files To fastqs subdirectory Verify the current directory is in the username directory. pwd Copy the 4 fastq.gz files and md5sum.txt, which you will use to check the validty of the files. cp /varidata/researchtemp/hpctmp/BBC/hpc_workshop_fqs/*fastq.gz ./fastqs/ cp /varidata/researchtemp/hpctmp/BBC/hpc_workshop_fqs/md5sum.txt ./fastqs/ Verify that the copied files are valid. The following code should return with an OK for each file. cd fastqs md5sum -c md5sum.txt ## SRR1039520_1.fastq.gz: OK ## SRR1039520_2.fastq.gz: OK ## SRR1039521_1.fastq.gz: OK ## SRR1039521_2.fastq.gz: OK Go back to the username directory. cd .. 3.4 Use basic Linux commands to explore the fastq files Notice all of the sequence data files end with a .gz extension, indicating they are gzip compressed. To view such files, one must use zcat instead of cat so that the files are decompressed into human-readable format. zcat fastqs/SRR1039520_1.fastq.gz | head ## @SRR1039520.19151550 19151550 length=63 ## CCAGGACATCAAGAAGCCAGCTGAAGATGAGTGGGGTAAAACCCCAGACGCCATGAAAGCTGC ## + ## HJJJJJJJJJJJJJJJIJJJJJJJJIJJJJJGGJJJFHIJIIJJIGHHFFFDDDDDCDDDCDD ## @SRR1039520.3404519 3404519 length=63 ## TGAGACATGGTTATAGATAAGAGAGTACAAAATGACTCTTTTTCCTGTCAATTGAAATTTAAA ## + ## HIGDFBGIIJBHGIIEHIIJIJIIIEGGIIIHGIJJIJJJIIJGIIIIGIEHIGDCHHIICG7 ## @SRR1039520.16253787 16253787 length=63 ## CAGGAGACCAAAGACACTGCAATTTGTGTGTTTTCTACAGGGTGCTTTAGATGACGTCTCATT zcat fastqs/SRR1039520_2.fastq.gz | head ## @SRR1039520.19151550 19151550 length=63 ## GAGATGGGGGTCCGTGCGGGCAGAACCCAGGGCATGAAGATCCAAAAGGGCCTGGTTCAGCTT ## + ## HJJJJJJJJJHHHIGIJIJJJJJJJHHHHFFFDDEEDDDDDDDDDDDDDDDDDDDDDDDDDDD ## @SRR1039520.3404519 3404519 length=63 ## TTTGACCCTAGTATTGGCAATAGCCCTTTGCTATTTATATAATTAAAACTTTTCTTTAAATTT ## + ## HIJIJJJJIIEHGIGIIIDGIJJJJIIJJJIJJJIJJJIIIJJJJIJJGCHIJJJJJIJIJII ## @SRR1039520.16253787 16253787 length=63 ## TACAGTTTGCAAAAGATGTCCAGATGGGTTCTTCTCAAATGAGACGTCATCTAAAGCACCCTG Notice that SRR1039520_1.fastq.gz and SRR1039520_2.fastq.gz files have the same read IDs. Valid paired fastq files always have matching read IDs throughout the entire file. Next, we can figure out how many reads are in a fastq file using wc -l. Recall that each read is represented by 4 lines in a fastq file, so we need to divide the results of wc -l by 4 to get the number of reads. zcat fastqs/SRR1039520_1.fastq.gz | wc -l ## 2000000 Finally, we can use wc -m to figure out the read length in a fastq file. Below, we use a combination of head -n2 and tail -n1 to get the second line of the first read. You may notice that the results of wc -m will be 1 higher than the actual read length. This is because the tool counts the newline character also. zcat fastqs/SRR1039520_1.fastq.gz | head -n2 | tail -n1 | wc -m ## 64 3.5 Working With Environment Modules Type module av bbc2 (modules beginning with just bbc are from the old HPC) to see all the software installed by the BBC. There are a lot of modules installed; to parse through these more easily, we can pipe the results of module av into grep to search for modules with specific keywords. There is a trick, though. The results of module av go to standard error, so we need to redirect standard error to standard out using 2&gt;&amp;1 before the pipe. This command will output any modules containing the fastqc keyword. module av -w 1 bbc2 2&gt;&amp;1 | grep &#39;fastqc&#39; ## bbc2/fastqc/fastqc-0.12.1 3.6 Run FastQC Create a fastqc directory inside of your username directory and run FastQC. module load bbc2/fastqc/fastqc-0.12.1 mkdir fastqc # Run FastQC. You can also run `fastqc -h` to see what different options do. fastqc -o fastqc fastqs/*fastq.gz ## application/gzip ## application/gzip ## Started analysis of SRR1039520_1.fastq.gz ## application/gzip ## application/gzip ## Approx 5% complete for SRR1039520_1.fastq.gz ## Approx 10% complete for SRR1039520_1.fastq.gz ## Approx 15% complete for SRR1039520_1.fastq.gz ## Approx 20% complete for SRR1039520_1.fastq.gz ## Approx 25% complete for SRR1039520_1.fastq.gz ## Approx 30% complete for SRR1039520_1.fastq.gz ## Approx 35% complete for SRR1039520_1.fastq.gz ## Approx 40% complete for SRR1039520_1.fastq.gz ## Approx 45% complete for SRR1039520_1.fastq.gz ## Approx 50% complete for SRR1039520_1.fastq.gz ## Approx 55% complete for SRR1039520_1.fastq.gz ## Approx 60% complete for SRR1039520_1.fastq.gz ## Approx 65% complete for SRR1039520_1.fastq.gz ## Approx 70% complete for SRR1039520_1.fastq.gz ## Approx 75% complete for SRR1039520_1.fastq.gz ## Approx 80% complete for SRR1039520_1.fastq.gz ## Approx 85% complete for SRR1039520_1.fastq.gz ## Approx 90% complete for SRR1039520_1.fastq.gz ## Approx 95% complete for SRR1039520_1.fastq.gz ## Approx 100% complete for SRR1039520_1.fastq.gz ## Analysis complete for SRR1039520_1.fastq.gz ## Started analysis of SRR1039520_2.fastq.gz ## Approx 5% complete for SRR1039520_2.fastq.gz ## Approx 10% complete for SRR1039520_2.fastq.gz ## Approx 15% complete for SRR1039520_2.fastq.gz ## Approx 20% complete for SRR1039520_2.fastq.gz ## Approx 25% complete for SRR1039520_2.fastq.gz ## Approx 30% complete for SRR1039520_2.fastq.gz ## Approx 35% complete for SRR1039520_2.fastq.gz ## Approx 40% complete for SRR1039520_2.fastq.gz ## Approx 45% complete for SRR1039520_2.fastq.gz ## Approx 50% complete for SRR1039520_2.fastq.gz ## Approx 55% complete for SRR1039520_2.fastq.gz ## Approx 60% complete for SRR1039520_2.fastq.gz ## Approx 65% complete for SRR1039520_2.fastq.gz ## Approx 70% complete for SRR1039520_2.fastq.gz ## Approx 75% complete for SRR1039520_2.fastq.gz ## Approx 80% complete for SRR1039520_2.fastq.gz ## Approx 85% complete for SRR1039520_2.fastq.gz ## Approx 90% complete for SRR1039520_2.fastq.gz ## Approx 95% complete for SRR1039520_2.fastq.gz ## Approx 100% complete for SRR1039520_2.fastq.gz ## Analysis complete for SRR1039520_2.fastq.gz ## Started analysis of SRR1039521_1.fastq.gz ## Approx 5% complete for SRR1039521_1.fastq.gz ## Approx 10% complete for SRR1039521_1.fastq.gz ## Approx 15% complete for SRR1039521_1.fastq.gz ## Approx 20% complete for SRR1039521_1.fastq.gz ## Approx 25% complete for SRR1039521_1.fastq.gz ## Approx 30% complete for SRR1039521_1.fastq.gz ## Approx 35% complete for SRR1039521_1.fastq.gz ## Approx 40% complete for SRR1039521_1.fastq.gz ## Approx 45% complete for SRR1039521_1.fastq.gz ## Approx 50% complete for SRR1039521_1.fastq.gz ## Approx 55% complete for SRR1039521_1.fastq.gz ## Approx 60% complete for SRR1039521_1.fastq.gz ## Approx 65% complete for SRR1039521_1.fastq.gz ## Approx 70% complete for SRR1039521_1.fastq.gz ## Approx 75% complete for SRR1039521_1.fastq.gz ## Approx 80% complete for SRR1039521_1.fastq.gz ## Approx 85% complete for SRR1039521_1.fastq.gz ## Approx 90% complete for SRR1039521_1.fastq.gz ## Approx 95% complete for SRR1039521_1.fastq.gz ## Approx 100% complete for SRR1039521_1.fastq.gz ## Analysis complete for SRR1039521_1.fastq.gz ## Started analysis of SRR1039521_2.fastq.gz ## Approx 5% complete for SRR1039521_2.fastq.gz ## Approx 10% complete for SRR1039521_2.fastq.gz ## Approx 15% complete for SRR1039521_2.fastq.gz ## Approx 20% complete for SRR1039521_2.fastq.gz ## Approx 25% complete for SRR1039521_2.fastq.gz ## Approx 30% complete for SRR1039521_2.fastq.gz ## Approx 35% complete for SRR1039521_2.fastq.gz ## Approx 40% complete for SRR1039521_2.fastq.gz ## Approx 45% complete for SRR1039521_2.fastq.gz ## Approx 50% complete for SRR1039521_2.fastq.gz ## Approx 55% complete for SRR1039521_2.fastq.gz ## Approx 60% complete for SRR1039521_2.fastq.gz ## Approx 65% complete for SRR1039521_2.fastq.gz ## Approx 70% complete for SRR1039521_2.fastq.gz ## Approx 75% complete for SRR1039521_2.fastq.gz ## Approx 80% complete for SRR1039521_2.fastq.gz ## Approx 85% complete for SRR1039521_2.fastq.gz ## Approx 90% complete for SRR1039521_2.fastq.gz ## Approx 95% complete for SRR1039521_2.fastq.gz ## Approx 100% complete for SRR1039521_2.fastq.gz ## Analysis complete for SRR1039521_2.fastq.gz See what was produced by FastQC. ls fastqc/ ## SRR1039520_1_fastqc.html ## SRR1039520_1_fastqc.zip ## SRR1039520_2_fastqc.html ## SRR1039520_2_fastqc.zip ## SRR1039521_1_fastqc.html ## SRR1039521_1_fastqc.zip ## SRR1039521_2_fastqc.html ## SRR1039521_2_fastqc.zip 3.7 Set up a job script to run Salmon to align the reads First, we exit from our interactive job because we want to get back on to the submit node to submit a non-interactive job to run Salmon. # You should see one job when you run this command, corresponding to your interactive job. squeue -u &lt;username&gt; # Exit the interactive job exit # Now you should see no jobs when you run this command because the interactive job has ended. squeue -u &lt;username&gt; # Go back to the project directory cd /varidata/researchtemp/hpctmp/BBC_workshop_June2023/&lt;username&gt; Below is a SLURM job script to run Salmon. For now, do not worry about how the code works. Copy the code and paste it into a new file. Save it as run_salmon.sh in your username directory. If you have issues with this task, you can copy the job script directly using the command, cp /varidata/researchtemp/hpctmp/BBC_workshop_June2023/kin.lau/run_salmon.sh .. #!/bin/bash #SBATCH --export=NONE #SBATCH -J run_salmon #SBATCH -o run_salmon.o #SBATCH -e run_salmon.e #SBATCH --ntasks 4 #SBATCH --time 1:00:00 #SBATCH --mem=36G start_time=$(date +&quot;%T&quot;) # You need to navigate to your project directory. Conveniently, the $SLURM_SUBMIT_DIR variable stores the path for where the job was submitted. cd ${SLURM_SUBMIT_DIR} module load bbc2/salmon/salmon-1.10.0 # Typically, you would have to first build an index before doing the aligning, but we have done this for you already. Here, we store the path to the index file in a variable called &#39;salmon_idx&#39;. salmon_idx=&quot;/varidata/research/projects/bbc/versioned_references/2022-03-08_14.47.50_v9/data/hg38_gencode/indexes/salmon/hg38_gencode/&quot; # make output directory for salmon mkdir -p salmon # This is called a for loop. We use this to run salmon quant on all the samples, one at a time. It is more efficient to run salmon on each sample &quot;in parallel&quot; but we will not do that today. for samp_id in SRR1039520 SRR1039521 do salmon quant -p ${SLURM_NTASKS} -l A -i $salmon_idx -1 fastqs/${samp_id}_1.fastq.gz -2 fastqs/${samp_id}_2.fastq.gz -o salmon/${samp_id} --validateMappings done end_time=$(date +&quot;%T&quot;) echo &quot;Start time: $start_time&quot; echo &quot;End time: $end_time&quot; 3.8 Submit a Job Type ls to ensure run_salmon.sh file exist in the username directory. ls Use the sbatch command to submit the job. sbatch -p big run_salmon.sh Users can check if the job is running with the following command. The job should take about two minutes to complete. squeue -u &lt;username&gt; 3.9 Examine the Standard Output (stdout) and Standard Error (stderr) log files It is good practice to check the job logs after your job is done to ensure that the job completed successfully. If there is an error, the output files may not be reliable or could be incomplete. tail run_salmon.e ## [2023-06-07 21:58:36.154] [jointLog] [info] iteration = 200 | max rel diff. = 0.491024 ## [2023-06-07 21:58:38.832] [jointLog] [info] iteration = 300 | max rel diff. = 3.96021 ## [2023-06-07 21:58:41.512] [jointLog] [info] iteration = 400 | max rel diff. = 0.644285 ## [2023-06-07 21:58:44.187] [jointLog] [info] iteration = 500 | max rel diff. = 0.323309 ## [2023-06-07 21:58:46.883] [jointLog] [info] iteration = 600 | max rel diff. = 0.287136 ## [2023-06-07 21:58:49.626] [jointLog] [info] iteration = 700 | max rel diff. = 0.814246 ## [2023-06-07 21:58:50.069] [jointLog] [info] iteration = 717 | max rel diff. = 0.00724807 ## [2023-06-07 21:58:50.107] [jointLog] [info] Finished optimizer ## [2023-06-07 21:58:50.107] [jointLog] [info] writing output tail run_salmon.o ## Start time: 21:57:16 ## End time: 21:58:51 3.10 Use grep to find the TPMs for a specific gene As an example, let’s try to extract out the TPMs (Transcripts per Million) for MUC1. These values can be found in the quant.sf file in each sample’s folder. First, let’s take a look at one of these files to figure out the format of these files. head salmon/SRR1039520/quant.sf ## Name Length EffectiveLength TPM NumReads ## ENST00000456328.2 1657 1502.194 0.000000 0.000 ## ENST00000450305.2 632 477.335 0.000000 0.000 ## ENST00000488147.1 1351 1196.194 0.000000 0.000 ## ENST00000619216.1 68 2.006 0.000000 0.000 ## ENST00000473358.1 712 557.286 0.000000 0.000 ## ENST00000469289.1 535 380.463 0.000000 0.000 ## ENST00000607096.1 138 25.002 0.000000 0.000 ## ENST00000417324.1 1187 1032.194 0.000000 0.000 ## ENST00000461467.1 590 435.379 0.000000 0.000 From the output above, we can see that the TPMs are in the 4th column of this file. The canonical transcript for MUC1 is ENST00000620103, so we will search for that using grep. grep &#39;ENST00000620103&#39; salmon/SRR1039520/quant.sf ## ENST00000620103.4 1811 1656.194 0.000000 0.000 Look for MUC1 across all the samples at the same time. We can see that ‘SRR1039521’ has a TPM of 13.1 for MUC1 compared to 0 for ‘SRR1039520’. Recall that the fastq files for this exercise were subsetted to a very small number of reads so don’t interpret these results seriously. grep &#39;ENST00000620103&#39; salmon/*/quant.sf ## salmon/SRR1039520/quant.sf:ENST00000620103.4 1811 1656.194 0.000000 0.000 ## salmon/SRR1039521/quant.sf:ENST00000620103.4 1811 1655.378 13.133596 5.717 3.11 BONUS: Use an interactive job to run multiQC on the Salmon and FastQC output In this final step, users will start an interactive job to perform multiQC to collect and summarize the outcomes from FastQC and Salmon, then evaluate the quality of the fastq sequences with the reference transcriptome(mapping rate). Start an interactive job. srun --nodes=1 --ntasks-per-node=1 --time=00:30:00 --pty bash Navigate to the project directory. cd /varidata/researchtemp/hpctmp/BBC_workshop_June2023/&lt;username&gt; Load the environment module for multiQC. module load bbc2/multiqc/multiqc-1.14 ## ## ### Loaded BBC module ## Loading this module prepends to $PYTHONPATH ## Don&#39;t use with conda. ## ### End BBC module message. Run multiQC, which will summarize the results from FastQC and Salmon and output the results into a new directory called multiqc/. multiqc --outdir multiqc . List the contents of the multiqc directory. ls multiqc ## multiqc_data ## multiqc_report.html Note the newly created multiqc_report.html file. Try to view this file in your preferred internet browser. If you have mounted the HPC file system to your computer, you can simply double-click on this file. Alternatively, you can copy this file to your computer’s local storage first and then open it. "],["basic-rna-seq-analysis-from-fastq-files-to-de-genes.html", "Part 4 Basic RNA-Seq Analysis – From fastq files to DE genes 4.1 Run the BBC pipeline to align the reads 4.2 Quality control 4.3 Exploring the data using iSEE 4.4 DE analysis using R and DESeq2 4.5 Some common plots for DEG analysis", " Part 4 Basic RNA-Seq Analysis – From fastq files to DE genes 4.1 Run the BBC pipeline to align the reads 4.1.1 The workflow as a graph The workflow. 4.1.2 Clone the Github repo Instructions for running it are on the Github README, but here we will go through each step in more detail. cd /varidata/researchtemp/hpctmp/BBC_workshop_June2023_II/ mkdir &lt;username&gt; cd &lt;username&gt; git clone https://github.com/vari-bbc/rnaseq_workflow.git The Github repository consisting of the RNA-seq workflow should now be downloaded in a folder named rnaseq_workflow. cd rnaseq_workflow ls 4.1.3 Add your fastq files to raw_data/ Instead of making multiple copies of the same file, which can quickly use up your lab’s storage quota, we can use symbolic links. The sequence data that we will be using for this workshop are from the airway dataset referenced in the DESeq2 vignette. The gene counts can actually be downloaded as an R package. ls ../../0_fastqs/ ln -sr ../../0_fastqs/* ./raw_data You can see where the symbolic links are pointing to using ls -l. ls -l ./raw_data 4.1.4 Fill out the samplesheet The samplesheet is a tab-delimited file within config/samplesheet/ and is named units.tsv. The easiest way to fill this out is to run the helper script, make_units_template.sh, to generate a template, then edit using a text editor. FOR THIS WORKSHOP, NO CHANGES NEED TO BE MADE. cd config/samplesheet/ ./make_units_template.sh There should now be a file named ‘units_template.tsv’. ls We can replace the ‘units.tsv’ with ‘units_template.tsv’. mv units_template.tsv units.tsv Go back to the base level of the project directory. cd ../.. Make sure you are at /varidata/researchtemp/hpctmp/BBC_workshop_June2023_II/&lt;username&gt;/rnaseq_workflow. pwd 4.1.5 Fill out the config file The config file is a YAML file indicating the locations of reference files and also contains options for the workflow that you can turn off or turn on. Typically, the main thing is to specify reference files corresponding to the species you have sequenced (human, mouse, or rat etc). For this workshop, we are dealing with human data so we will align to the hg38 reference. Index files allow alignment algorithms to align reads to specific reference sequences. FOR THIS WORKSHOP, NO CHANGES NEED TO BE MADE. cat config/config.yaml 4.1.6 Submit the main Snakemake job sbatch -p big bin/run_snake.sh 4.1.7 BBC-maintained reference files For future reference, the BBC downloads and maintains commonly used files and indexes for several model species. These files are version controlled to promote reproducibility in case you need to rerun an analysis or you want to run the exact same analysis on different datasets. ls /varidata/research/projects/bbc/versioned_references/ ## 2021-04-09_12.44.55_v1 ## 2021-07-02_11.23.48_v3 ## 2021-07-13_09.57.31_v4 ## 2021-08-02_20.40.24_v5 ## 2021-08-10_11.12.27_v6 ## 2021-10-25_15.31.38_v7 ## 2022-01-26_13.39.07_v8 ## 2022-03-08_14.47.50_v9 ## 2022-10-06_14.25.40_v10 ## 2022-12-19_13.27.04_v11 ## 2023-05-03_15.28.41_v12 ## latest ## regarding_v2.txt ls /varidata/research/projects/bbc/versioned_references/2023-05-03_15.28.41_v12/data/ ## GRCz11 ## c.elegans-WBcel235 ## dm6_BDGP6.28.100 ## e.coli-K12-mg1665_ensembl ## hg19_gencode ## hg19_gencode_plus_ERCC92 ## hg19_gencode_plus_viruses ## hg38_gencode ## mm10_gencode ## mm10_gencode_plus_ERCC92 ## mm10_gencode_plus_e.coli-K12-mg1665_ensembl ## mm10_gencode_plus_viruses_and_cfmedips ## mm11_gencode ## mm9_ucsc ## mm_BALB_CJ ## mm_BALB_CJ_plus_viruses_and_cfmedips ## mm_FVB_NJ ## mm_FVB_NJ_plus_viruses_and_cfmedips ## rnor6_ensembl The source of these files can be found in the species.tsv file. cat /varidata/research/projects/bbc/versioned_references/2023-05-03_15.28.41_v12/bin/species.tsv | cut -f2-3 ## id genome_fasta ## mm10_gencode ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M24/GRCm38.primary_assembly.genome.fa.gz ## hg38_gencode ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_33/GRCh38.primary_assembly.genome.fa.gz ## e.coli-K12-mg1665_ensembl ftp://ftp.ensemblgenomes.org/pub/release-47/bacteria//fasta/bacteria_0_collection/escherichia_coli_str_k_12_substr_mg1655/dna/Escherichia_coli_str_k_12_substr_mg1655.ASM584v2.dna.chromosome.Chromosome.fa.gz ## hg19_gencode ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_36/GRCh37_mapping/GRCh37.primary_assembly.genome.fa.gz ## dm6_BDGP6.28.100 ftp://ftp.ensembl.org/pub/release-100/fasta/drosophila_melanogaster/dna/Drosophila_melanogaster.BDGP6.28.dna.toplevel.fa.gz ## c.elegans-WBcel235 http://ftp.ensembl.org/pub/release-103/fasta/caenorhabditis_elegans/dna/Caenorhabditis_elegans.WBcel235.dna.toplevel.fa.gz ## mm_BALB_CJ http://ftp.ensembl.org/pub/release-104/fasta/mus_musculus_balbcj/dna/Mus_musculus_balbcj.BALB_cJ_v1.dna.toplevel.fa.gz ## mm_FVB_NJ http://ftp.ensembl.org/pub/release-104/fasta/mus_musculus_fvbnj/dna/Mus_musculus_fvbnj.FVB_NJ_v1.dna.toplevel.fa.gz ## rnor6_ensembl http://ftp.ensembl.org/pub/release-104/fasta/rattus_norvegicus/dna/Rattus_norvegicus.Rnor_6.0.dna.toplevel.fa.gz ## GRCz11 https://ftp.ensembl.org/pub/release-108/fasta/danio_rerio/dna/Danio_rerio.GRCz11.dna.toplevel.fa.gz ## mm11_gencode https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M31/GRCm39.primary_assembly.genome.fa.gz ## mm9_ucsc ftp://hgdownload.cse.ucsc.edu/goldenPath/mm9/bigZips/mm9.fa.gz The verions of the software used to generate the index files can be found in the config.yaml file. Sometimes index files are not backwards-compatible, meaning index files generated by a newer version of a tool cannot be used by an older version of the tool. cat /varidata/research/projects/bbc/versioned_references/2023-05-03_15.28.41_v12/bin/config.yaml ## # This is the directory that the rsync rule will use as the source directory. It shuold be the run directory this workflow. ## sourceDir: &quot;/varidata/research/projects/bbc/research/prep_bbc_shared_current&quot; ## ## # This is where the timestamped directories and the &#39;latest&#39; symlink will be created. ## timestamp_dir: &quot;/varidata/research/projects/bbc/versioned_references/&quot; ## ## # Environment modules used. ## # Specify all environment modules here instead of within the Snakefile itself to make it easy to look over quickly. ## # When aligning using the index files created by this workflow, use the same version aligner as listed here to ensure compatibility. ## samtools: &quot;bbc/samtools/samtools-1.9&quot; ## picard: &quot;bbc/picard/picard-2.21.4-SNAPSHOT&quot; ## STAR: &quot;bbc/STAR/STAR-2.7.8a&quot; ## biscuit: &quot;bbc/biscuit/biscuit_1_0_1&quot; ## bwa: &quot;bbc/bwa/bwa-0.7.17&quot; ## bowtie2: &quot;bbc/bowtie2/bowtie2-2.4.1&quot; ## python3: &quot;bbc/python3/python-3.8.1&quot; ## bismark: &quot;bbc/bismark/bismark-0.23.0&quot; ## kb-python: &quot;bbc/kb-python/kb-python-0.24.4&quot; ## parallel: &quot;bbc/parallel/parallel-20191122&quot; ## gsutil: &quot;bbc/gsutil/gsutil-4.52&quot; ## seqtk: &quot;bbc/seqtk/seqtk-1.3-r115-dirty&quot; ## salmon: &quot;bbc/salmon/salmon-1.4.0&quot; ## kallisto: &quot;bbc/kallisto/kallisto-0.46.1&quot; 4.2 Quality control It’s important to look through QC metrics to ensure that the data is likely to produce meaningful results. Ideally, you don’t want to waste time trying to interpret bad data. 4.2.1 multiQC report Navigate to your project folder using Finder (Mac) or File Explorer (Windows). Find results/multiqc/multiqc_report.html and double-click it. Alignment rate? Higher duplication rate can be normal for RNA-seq. Strandedness; In our workflow, this is automatically inferred using Salmon. Any contamination? Check FastqScreen results. 4.2.2 Other considerations Not a bad idea to look quickly at the alignments in IGV. Any sign of gDNA contamination? Mutations in specific genotypes? Is it exonic? Can do a quick check in IGV. How many genes expressed? Easy to check in R. Marker genes? Can do a quick check in iSEE if you expect certain expression patterns between groups. Any genes supposed to knocked out or knocked down? Use iSEE. Does the PCA show clustering? Use iSEE. 4.3 Exploring the data using iSEE Navigate to your project folder using Finder (Mac) or File Explorer (Windows). Find iSEE/app.R and double-click it. iSEE screenshot. 4.4 DE analysis using R and DESeq2 4.4.1 Make an output directory outdir &lt;- &quot;./deseq2_out_files/&quot; dir.create(outdir, recursive=TRUE) 4.4.2 Load packages suppressMessages(library(dplyr)) library(stringr) library(ggplot2) library(readr) library(ggrepel) suppressMessages(library(ComplexHeatmap)) suppressMessages(library(DESeq2)) 4.4.3 Set up your DESeq object se &lt;- readRDS(&quot;../results/SummarizedExperiment/SummarizedExperiment.rds&quot;) Let’s take a look to see what assays are stored in the SummarizedExperiment object. Note that DESeq2 assumes the first assay is the raw counts. assayNames(se) ## [1] &quot;counts&quot; &quot;tpms&quot; &quot;vst&quot; stopifnot(assayNames(se)[1] == &quot;counts&quot;) To print more information about this SummarizedExperiment object, you can just type its name. se ## class: SummarizedExperiment ## dim: 60721 8 ## metadata(0): ## assays(3): counts tpms vst ## rownames(60721): ENSG00000223972.5 ENSG00000227232.5 ... ## ENSG00000278625.1 ENSG00000277374.1 ## rowData names(4): Symbol Uniq_syms entrez Gene_name ## colnames(8): SRR1039509 SRR1039513 ... SRR1039516 SRR1039520 ## colData names(2): sample group The counts and the meta data need to be stored inside a special DESeq2 object called a ‘DESeqDataSet’. Here, we also specify that each gene will be fit with a model design of ‘~ group’. dds &lt;- DESeqDataSet(se, design = ~ group) ## converting counts to integer mode ## Warning in DESeqDataSet(se, design = ~group): some variables in design formula ## are characters, converting to factors 4.4.4 Remove genes with low/no expression We cannot do meaningful analyses of genes with very low counts. This will speed up the analysis. # prefilter genes, keeping only genes with 10 or more total read counts across samples keep &lt;- rowSums(counts(dds)) &gt;= 10 message(str_glue(&quot;Keeping {sum(keep)} genes.&quot;)) ## Keeping 21485 genes. dds &lt;- dds[keep, ] 4.4.5 Different normalization approaches for different biases Types of biases in RNA-seq 4.4.6 Run the DE workflow The DESeq function is a convenience function from DESeq2 that estimates size factors (normalization) and fits negative binomial GLMs. dds &lt;- DESeq(dds) ## estimating size factors ## estimating dispersions ## gene-wise dispersion estimates ## mean-dispersion relationship ## final dispersion estimates ## fitting model and testing message(paste0(&quot;Coefficient names are: &quot;, paste(resultsNames(dds), collapse = &quot; &quot;))) ## Coefficient names are: Intercept group_untrt_vs_trt After the models are fitted, we can test specific pairs of groups for differential expression. For DESeq2, it is recommended to provide the significance cutoff that you wish to use as it affects the multiple testing correction procedure (see docs). contrast &lt;- c(&quot;group&quot;, &quot;trt&quot;, &quot;untrt&quot;) fdr_cutoff &lt;- 0.1 res &lt;- results(dds, contrast=contrast, alpha=fdr_cutoff) res &lt;- res[order(res$pvalue), ] 4.4.7 Summarize DE results df &lt;- as.data.frame(res) data.frame( UP=sum(df$padj &lt;= fdr_cutoff &amp; df$log2FoldChange &gt; 0, na.rm = TRUE), DWN=sum(df$padj &lt;= fdr_cutoff &amp; df$log2FoldChange &lt; 0, na.rm = TRUE), Tested=sum(!is.na(df$padj)) ) ## UP DWN Tested ## 1 1872 1481 17272 4.4.8 Shrink log fold changes for lowly expressed genes This step does not affect the identification of DE genes, but it can be useful to perform this to obtain more reliable estimates of the log fold changes for visualizations or for ranking genes (e.g. GSEA). lfc_shrink &lt;- lfcShrink(dds, contrast=contrast, type=&quot;ashr&quot;) ## using &#39;ashr&#39; for LFC shrinkage. If used in published research, please cite: ## Stephens, M. (2016) False discovery rates: a new deal. Biostatistics, 18:2. ## https://doi.org/10.1093/biostatistics/kxw041 lfc_shrink &lt;- lfc_shrink[order(lfc_shrink$pvalue), ] DESeq2::plotMA(res, main=&quot;Default LFC&quot;) DESeq2::plotMA(lfc_shrink, main=&quot;Shrunken LFC&quot;) 4.4.9 Output DE results Here, we merge the different gene name columns to the DE results and output to a tab-delimited file, which can be opened in Excel for manual perusal. df &lt;- cbind(as.data.frame(rowData(dds)[rownames(lfc_shrink), 1:4]), as.data.frame(lfc_shrink)) %&gt;% tibble::rownames_to_column(&quot;ens_gene&quot;) write_tsv(df, file.path(outdir, &quot;de_res.tsv&quot;)) 4.4.10 Look for specific genes We know certain genes should be differentially expressed based on the paper that this dataset came from. We can check that these genes were significantly DE in our analysis. Likewise, this would be a good time to check for knocked down, knocked out etc genes if such prior knowledge is available, though that is not always the case. df %&gt;% dplyr::filter(Symbol %in% c(&quot;DUSP1&quot;, &quot;KLF15&quot;, &quot;CRISPLD2&quot;)) ## ens_gene Symbol Uniq_syms entrez ## 1 ENSG00000120129.6 DUSP1 DUSP1 1843 ## 2 ENSG00000163884.4 KLF15 KLF15 28999 ## 3 ENSG00000103196.12 CRISPLD2 CRISPLD2 83716 ## Gene_name baseMean ## 1 dual specificity phosphatase 1 3357.1543 ## 2 KLF transcription factor 15 551.1765 ## 3 cysteine rich secretory protein LCCL domain containing 2 2875.4571 ## log2FoldChange lfcSE pvalue padj ## 1 2.899715 0.1982447 9.251009e-50 3.195669e-46 ## 2 4.325184 0.4142733 2.361153e-28 1.568532e-25 ## 3 2.618796 0.2590196 2.407565e-25 1.144831e-22 4.4.11 Output tables with raw counts Some folks also find it useful to have tables of the raw counts or the normalized counts. The raw counts can be extracted from the DESeq2 object using either assay() or counts(). df &lt;- cbind(as.data.frame(rowData(dds)[, 1:4]), assay(dds, &quot;counts&quot;)) %&gt;% tibble::rownames_to_column(&quot;ens_gene&quot;) write_tsv(df, file.path(outdir, &quot;counts.tsv&quot;)) 4.4.12 Output tables with log2 normalized counts For the log2 normalized counts, we commonly use the variance stabilized transformation (VST). These values can be used for heatmaps, clustering or other downstream applications. vsd &lt;- vst(dds, blind=FALSE) vst_df &lt;- as.data.frame(cbind(rowData(vsd)[, 1:4], assay(vsd))) %&gt;% tibble::rownames_to_column(&quot;ens_gene&quot;) write_tsv(vst_df, file.path(outdir, &quot;vst.tsv&quot;)) 4.5 Some common plots for DEG analysis 4.5.1 Volcano plot make_volcano &lt;- function(df, pval_nm, pval_cutoff=0.1){ # remove genes with NA for pvalue df &lt;- df[which(!is.na(df[[pval_nm]])), ] # add gene names df &lt;- cbind(df, rowData(dds)[rownames(df), 1:4]) top_genes &lt;- df %&gt;% dplyr::arrange(desc(abs(df$log2FoldChange))) %&gt;% dplyr::filter(row_number() &lt;= 10) %&gt;% rownames() df$Sig &lt;- ifelse(df$padj &lt;= pval_cutoff, &quot;Sig&quot;, &quot;NS&quot;) df[[pval_nm]] &lt;- -log10(df[[pval_nm]]) ggplot(df, aes_string(x=&quot;log2FoldChange&quot;, y=pval_nm)) + geom_point(aes(color=Sig), size=0.6) + scale_color_manual(values=c(&quot;black&quot;, &quot;salmon&quot;)) + theme_bw() + ylab(str_glue(&quot;-log10(&quot;, pval_nm,&quot;)&quot;)) + geom_text_repel(data=df[top_genes, ], aes(label=Uniq_syms), max.overlaps=Inf, min.segment.length = 0) } make_volcano(as.data.frame(lfc_shrink), pval_nm=&quot;padj&quot;, pval_cutoff=fdr_cutoff) ## Warning: `aes_string()` was deprecated in ggplot2 3.0.0. ## ℹ Please use tidy evaluation idioms with `aes()`. ## ℹ See also `vignette(&quot;ggplot2-in-packages&quot;)` for more information. ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was generated. 4.5.2 Heatmap top_genes &lt;- rownames(res)[1:20] top_se &lt;- se[top_genes, ] mat &lt;- assay(top_se, &quot;vst&quot;) mat &lt;- t(scale(t(mat), scale=FALSE, center = TRUE)) # column annot ht_col_annot &lt;- as.data.frame(colData(top_se)[, &quot;group&quot;, drop=FALSE]) group_lvls &lt;- unique(ht_col_annot$group) ht_col_colors &lt;- list(group=setNames(c(&quot;#440154FF&quot;,&quot;#2A788EFF&quot;), nm=group_lvls)) Heatmap(mat, name = &quot;Mean-centered&quot;, cluster_columns = FALSE, row_labels=rowData(top_se)$Uniq_syms, show_column_names = FALSE, top_annotation=HeatmapAnnotation(df=ht_col_annot, col=ht_col_colors), column_title = &quot;Top DE genes&quot;, row_title = paste0(nrow(mat), &quot; genes&quot;) ) 4.5.3 P value distribution Ideally, we will see an anti-conservative (if there are many DE genes) or uniform pattern (not many DE genes). See here for more details about how to interpret these. ggplot(data = as.data.frame(lfc_shrink) %&gt;% dplyr::filter(!is.na(pvalue)), aes(x = pvalue)) + geom_histogram(color = &quot;black&quot;, fill = &quot;gray55&quot;, breaks = seq(0, 1, 0.05)) + theme_bw() + theme(plot.title=element_text(size=10)) "],["pathway-enrichment-and-experimental-design.html", "Part 5 Pathway, enrichment, and experimental design 5.1 Downstream of DE gene analysis", " Part 5 Pathway, enrichment, and experimental design 5.1 Downstream of DE gene analysis 5.1.1 Copy the project directory You will make your own directory, and copy the directory containing data and R code into your own. cd /varidata/researchtemp/hpctmp/BBC_workshop_June2023_III/ mkdir &lt;username&gt; cd &lt;username&gt; pwd ## make sure you are in your dir cp -r ../workshopIII_files . cd workshopIII_files ls "],["appendices.html", "Part 6 Appendices 6.1 Workshop Powerpoint files 6.2 Local access of files on the HPC 6.3 Bash cheatsheet", " Part 6 Appendices 6.1 Workshop Powerpoint files June 8, 2023; Summer workshop I 6.2 Local access of files on the HPC Mac: 1. Click Finder &gt; “Go” in task bar &gt; “Connect to Server” in the pulldown menu. 2. Type smb://pn.vai.org and click “Connect”. 3. Select ‘projects’ and ‘researchtemp’. Click “OK”. 4. You can now navigate using Finder, or type ls /Volumes/projects/ or ls /Volumes/researchtemp/ in the Terminal. Windows: * In File Explorer, type \\\\pn.vai.org\\ and hit Enter. 6.3 Bash cheatsheet Name Command Line Description Example Print Working Directory pwd Displays the current working directory [username\\@submit002 ~]$ pwd Result:/home/username List ls Lists the files and directories in the current directory [username\\@submit002 ~]$ ls Result: It returns empty after the $ symbol since nothing has been created. List More Detail ls -lht Display more details about the file [username\\@submit002 ~]$ ls -lht Result: Display file detail in the current director Make Directory mkdir Creates a new directory [username\\@submit002 ~]$ mkdir hpc_mini_workshop Result: A hpc_mini_workshop folder is created. Move mv Moves or renames files or directories [username\\@submit002 ~]$ mv hpc_mini_workshop workshopTraining Result: Now the hpc_mini_workshop directory is called workshopTraining Change Directory cd Change to an existing directory [username\\@submit002 ~]$ cd workshopTraining Result: [username@submit002 workshopTraining]$ Notice ~ was in the home directory, now in the workshopTraining directory. Remove rm Deletes files and directories [username\\@submit002 ~]$ rm -r TaskProject *Note: -r means directory Result: TaskProject is deleted Copy cp Copies files or directories [username\\@submit002 ~]$ cp -r Task1 Project Result: Task1 directory has moved to the Project directory. Search for File find Search for files and directories based on various criteria like name, size, and modification time [username\\@submit002 ~]$ find Project Result: Task1 will appear within the Project directory Project Project/Task1 Head head Display at the beginning of a file [username\\@submit002 ~]$ head -n5 file_name Result: It will display the first 5 lines from the beginning of the file_name. Tail tail Display at the end of a file [username\\@submit002 ~]$ tail -n5 file_name Result: It will display the last 5 lines from the end of the file_name Less less Load the necessary portion of a file [username\\@submit002 ~]$ less file.txt Result: The user is able to view a portion of the file.txt. More more Load the entire file [username\\@submit002 ~]$ more file.txt Result: The user is able to view the entire file.txt. Quit q Stop viewing the current file quit viewing the current file Concatenate cat Display the contents of a file [username\\@submit002 ~]$ cat file.txt Result: Display the contents of file.txt Search for Text grep Search for a specific pattern of text within files [username\\@submit002 ~]$ grep “GCGGA” sequence_file.fastq Result: Display any GCGGA pattern in sequence_file.fastq Word, Line, and Character Count wc Display the number of words, lines, and characters in a file [username\\@submit002 ~]$ wc file.txt Result: Display the number of words, lines, and characters in the file.txt. Touch touch Create a new empty file [username\\@submit002 ~]$ touch exampleFile.txt Result: The command line will display file details in the current directory "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
